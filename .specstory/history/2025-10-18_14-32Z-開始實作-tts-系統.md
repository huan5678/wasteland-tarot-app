<!-- Generated by SpecStory -->

<!-- cursor Session 89b7e271-cbe0-4604-95df-b7c7604c5cf3 (2025-10-18 14:32Z) -->

# é–‹å§‹å¯¦ä½œ TTS ç³»çµ± (2025-10-18 14:32Z)

_**User (2025-11-03 16:17Z)**_

/kiro/spec-init é–‹å§‹å¯¦ä½œ TTS ç³»çµ±ä½¿ç”¨ https://cloud.google.com/text-to-speech/docs/chirp3-hd?hl=zh-tw Chirp 3ï¼šHD çš„æ¨¡å‹ä¾†å®Œæˆ

--- Cursor Command: kiro/spec-init.md ---

# Spec Initialization

<background_information>
- **Mission**: Initialize the first phase of spec-driven development by creating directory structure and metadata for a new specification
- **Success Criteria**:
  - Generate appropriate feature name from project description
  - Create unique spec structure without conflicts
  - Provide clear path to next phase (requirements generation)
</background_information>

<instructions>
## Core Task
Generate a unique feature name from the project description (é–‹å§‹å¯¦ä½œ TTS ç³»çµ±ä½¿ç”¨ https://cloud.google.com/text-to-speech/docs/chirp3-hd?hl=zh-tw Chirp 3ï¼šHD çš„æ¨¡å‹ä¾†å®Œæˆ) and initialize the specification structure.

## Execution Steps
1. **Check Uniqueness**: Verify `.kiro/specs/` for naming conflicts (append number suffix if needed)
2. **Create Directory**: `.kiro/specs/[feature-name]/`
3. **Initialize Files Using Templates**:
   - Read `.kiro/settings/templates/specs/init.json`
   - Read `.kiro/settings/templates/specs/requirements-init.md`
   - Replace placeholders:
     - `{{FEATURE_NAME}}` â†’ generated feature name
     - `{{TIMESTAMP}}` â†’ current ISO 8601 timestamp
     - `{{PROJECT_DESCRIPTION}}` â†’ é–‹å§‹å¯¦ä½œ TTS ç³»çµ±ä½¿ç”¨ https://cloud.google.com/text-to-speech/docs/chirp3-hd?hl=zh-tw Chirp 3ï¼šHD çš„æ¨¡å‹ä¾†å®Œæˆ
   - Write `spec.json` and `requirements.md` to spec directory

## Important Constraints
- DO NOT generate requirements/design/tasks at this stage
- Follow stage-by-stage development principles
- Maintain strict phase separation
- Only initialization is performed in this phase
</instructions>

## Tool Guidance
- Use **Glob** to check existing spec directories for name uniqueness
- Use **Read** to fetch templates: `init.json` and `requirements-init.md`
- Use **Write** to create spec.json and requirements.md after placeholder replacement
- Perform validation before any file write operation

## Output Description
Provide output in the language specified in `spec.json` with the following structure:

1. **Generated Feature Name**: `feature-name` format with 1-2 sentence rationale
2. **Project Summary**: Brief summary (1 sentence)
3. **Created Files**: Bullet list with full paths
4. **Next Step**: Command block showing `/kiro:spec-requirements <feature-name>`
5. **Notes**: Explain why only initialization was performed (2-3 sentences on phase separation)

**Format Requirements**:
- Use Markdown headings (##, ###)
- Wrap commands in code blocks
- Keep total output concise (under 250 words)
- Use clear, professional language per `spec.json.language`

## Safety & Fallback
- **Ambiguous Feature Name**: If feature name generation is unclear, propose 2-3 options and ask user to select
- **Template Missing**: If template files don't exist in `.kiro/settings/templates/specs/`, report error with specific missing file path and suggest checking repository setup
- **Directory Conflict**: If feature name already exists, append numeric suffix (e.g., `feature-name-2`) and notify user of automatic conflict resolution
- **Write Failure**: Report error with specific path and suggest checking permissions or disk space
--- End Command ---

---

_**Assistant (claude-4.5-sonnet)**_

<think><details><summary>Thought Process</summary>The user is asking me to run the `/kiro/spec-init` command to start implementing a TTS system using Google Cloud's Chirp 3:HD model. Let me analyze the project description:
</details></think>

---

Tool use: **list_dir**

<details>
            <summary>Listed directory undefined â€¢ **0** results</summary>
        
No results found
</details>

---

<think><details><summary>Thought Process</summary>I can see the existing specs. Now I need to generate a unique feature name from the project description "é–‹å§‹å¯¦ä½œ TTS ç³»çµ±ä½¿ç”¨ https://cloud.google.com/text-to-speech/docs/chirp3-hd?hl=zh-tw Chirp 3ï¼šHD çš„æ¨¡å‹ä¾†å®Œæˆ".

Since there is no ExistingSummary provided, I'll start with a new subheading based on the NewReasoningContent.</details></think>

---

Tool use: **read_file**

Read file: .kiro/settings/templates/specs/init.json

---

<think><details><summary>Thought Process</summary>Good, I got the init.json template. Now let me read the requirements-init.md template.</details></think>

---

Tool use: **read_file**

Read file: .kiro/settings/templates/specs/requirements-init.md

---

<think><details><summary>Thought Process</summary>Perfect! Now I have both templates. Let me generate the feature name and create the spec structure.
</details></think>

---

Tool use: **run_terminal_cmd**

```bash
date -u +"%Y-%m-%dT%H:%M:%SZ"
```

```
2025-11-03T16:19:08Z

```

---

<think><details><summary>Thought Process</summary>Great! Now I have the timestamp: 2025-11-03T16:19:08Z
</details></think>

---

Tool use: **run_terminal_cmd**

```bash
mkdir -p .kiro/specs/chirp3-hd-tts-system
```

---

<think><details><summary>Thought Process</summary>Good, directory created. Now I need to create the spec.json file by replacing the placeholders in the template.


## Preparing Spec File  
- Found a template for the spec.json file with placeholders for feature name and timestamp.</details></think>

---

Tool use: **write**


<details><summary>Edit file: .kiro/specs/chirp3-hd-tts-system/spec.json</summary>

**Chunk 1**
Lines added: 22, lines removed: 1

```diff
@@ -1,1 +1,22 @@
- 
+ {
+   "feature_name": "chirp3-hd-tts-system",
+   "created_at": "2025-11-03T16:19:08Z",
+   "updated_at": "2025-11-03T16:19:08Z",
+   "language": "en",
+   "phase": "initialized",
+   "approvals": {
+     "requirements": {
+       "generated": false,
+       "approved": false
+     },
+     "design": {
+       "generated": false,
+       "approved": false
+     },
+     "tasks": {
+       "generated": false,
+       "approved": false
+     }
+   },
+   "ready_for_implementation": false
+ }
```

</details>

---

<think><details><summary>Thought Process</summary>Good! Now I need to create the requirements.md file with the placeholder replacements.
</details></think>

---

Tool use: **write**


<details><summary>Edit file: .kiro/specs/chirp3-hd-tts-system/requirements.md</summary>

**Chunk 1**
Lines added: 7, lines removed: 1

```diff
@@ -1,1 +1,7 @@
- 
+ # Requirements Document
+ 
+ ## Project Description (Input)
+ é–‹å§‹å¯¦ä½œ TTS ç³»çµ±ä½¿ç”¨ https://cloud.google.com/text-to-speech/docs/chirp3-hd?hl=zh-tw Chirp 3ï¼šHD çš„æ¨¡å‹ä¾†å®Œæˆ
+ 
+ ## Requirements
+ <!-- Will be generated in /kiro:spec-requirements phase -->
```

</details>

---

<think><details><summary>Thought Process</summary>Perfect! I've successfully created the spec initialization. Now I need to provide the output in the specified format. Since the user rules specify to respond in Traditional Chinese (zh-tw), I'll do that despite the spec.json language being "en".
</details></think>

---

ğŸ¤–

## ç”¢ç”Ÿçš„åŠŸèƒ½åç¨±
`chirp3-hd-tts-system` - æ ¹æ“šå°ˆæ¡ˆæè¿°ã€Œå¯¦ä½œ TTS ç³»çµ±ä½¿ç”¨ Google Chirp 3ï¼šHD æ¨¡å‹ã€ï¼Œé€™å€‹åç¨±æº–ç¢ºåæ˜ äº†ä½¿ç”¨ Google Cloud Text-to-Speech Chirp 3ï¼šHD æ¨¡å‹çš„æ ¸å¿ƒæŠ€è¡“éœ€æ±‚ã€‚

## å°ˆæ¡ˆæ‘˜è¦
å¯¦ä½œåŸºæ–¼ Google Cloud Chirp 3ï¼šHD æ¨¡å‹çš„æ–‡å­—è½‰èªéŸ³ç³»çµ±ã€‚

## å»ºç«‹çš„æª”æ¡ˆ
- `.kiro/specs/chirp3-hd-tts-system/spec.json`
- `.kiro/specs/chirp3-hd-tts-system/requirements.md`

## ä¸‹ä¸€æ­¥
```bash
/kiro:spec-requirements chirp3-hd-tts-system
```

## å‚™è¨»
æœ¬æ¬¡åªé€²è¡Œåˆå§‹åŒ–éšæ®µï¼Œé¿å…éæ—©é€²å…¥éœ€æ±‚åˆ†æã€è¨­è¨ˆå’Œä»»å‹™è¦åŠƒã€‚éµå¾ªéšæ®µåˆ†é›¢åŸå‰‡ï¼Œç¢ºä¿æ¯å€‹é–‹ç™¼éšæ®µéƒ½æœ‰é©ç•¶çš„å¯©æ ¸å’Œç¢ºèªæ©Ÿåˆ¶ï¼Œé€™æ¨£å¯ä»¥ç¶­æŒé–‹ç™¼éç¨‹çš„å“è³ªå’Œå¯æ§æ€§ã€‚

---

_**User (2025-11-03 16:17Z)**_

/kiro:spec-requirements chirp3-hd-tts-system

---

_**Assistant (claude-4.5-sonnet)**_

<think><details><summary>Thought Process</summary>The user is now running the `/kiro:spec-requirements` command for the `chirp3-hd-tts-system` feature. This is the next phase in the spec-driven development process.


## Examining command purpose  
- The user initiated the `/kiro:spec-requirements` command for the `chirp3-hd-tts-system` feature.</details></think>

---

Tool use: **read_file**

Read file: .kiro/specs/chirp3-hd-tts-system/spec.json

---

<think><details><summary>Thought Process</summary>Now let me read the current requirements.md to see what needs to be updated.</details></think>

---

Tool use: **read_file**

Read file: .kiro/specs/chirp3-hd-tts-system/requirements.md

---

<think><details><summary>Thought Process</summary>Now I need to understand the project better. The project description is in Chinese: "é–‹å§‹å¯¦ä½œ TTS ç³»çµ±ä½¿ç”¨ https://cloud.google.com/text-to-speech/docs/chirp3-hd?hl=zh-tw Chirp 3ï¼šHD çš„æ¨¡å‹ä¾†å®Œæˆ" which translates to "Start implementing TTS system using https://cloud.google.com/text-to-speech/docs/chirp3-hd?hl=zh-tw Chirp 3:HD model to complete".
</details></think>

---

Tool use: **grep**

<details>
<summary>Grep for "tts|TTS|speech|audio|voice" â€¢ 373 matches</summary>

Output mode: files_with_matches


| File |
|------|
| `./backend/alembic/versions/20251104_gpql23ivbb2v_upgrade_user_karma_dual_score.py` |
| `./backend/app/models/gamification.py` |
| `./backend/app/models/__init__.py` |
| `./backend/app/models/user.py` |
| `./src/types/session.ts` |
| `./src/types/database.ts` |
| `./src/types/api.ts` |
| `./src/test/mocks/handlers/cards.ts` |
| `./src/stores/metadataStore.ts` |
| `./src/stores/cardsStore.ts` |
| `./src/lib/stores/playlistStore.ts` |
| `./src/lib/readingsStore.ts` |
| `./src/lib/audio/rewardSounds.ts` |
| `./src/lib/audio/effects/EffectsProcessor.ts` |
| `./src/lib/audio/drums/DrumKit.ts` |
| `./src/lib/audio/RhythmAudioSynthesizer.ts` |
| `./src/lib/audio/ProceduralMusicEngine.ts` |
| `./src/lib/api/services.ts` |
| `./src/lib/api.ts` |
| `./src/lib/__tests__/api-story.test.ts` |
| `./src/hooks/useStoryAudio.ts` |
| `./src/hooks/usePreferences.ts` |
| `./src/hooks/useCharacterVoices.ts` |
| `./src/hooks/useCardEnhancement.ts` |
| `./src/data/enhancedCards.ts` |
| `./src/components/ui/pipboy/__tests__/PipBoyCard.test.tsx` |
| `./src/components/ui/pipboy/__tests__/PipBoyButton.test.tsx` |
| `./src/components/ui/pipboy/PipBoyCard.tsx` |
| `./src/components/ui/pipboy/PipBoyButton.tsx` |
| `./src/components/ui/dialog.tsx` |
| `./src/components/ui/card.tsx` |
| `./src/components/ui/button.tsx` |
| `./src/components/tarot/StudyMode.tsx` |
| `./src/components/tarot/StorySection.tsx` |
| `./src/components/tarot/StoryAudioPlayer.tsx` |
| `./src/components/tarot/CharacterVoiceSelector.tsx` |
| `./src/components/tarot/CardShare.tsx` |
| `./src/components/tarot/CardDetailModal.tsx` |
| `./src/components/system/AudioInitializer.tsx` |
| `./src/components/readings/StreamingInterpretation.tsx` |
| `./src/components/readings/ReadingHistory.tsx` |
| `./src/components/readings/ReadingDetailModal.tsx` |
| `./src/components/readings/ReadingCardDetail.tsx` |
| `./src/components/readings/CarouselContainer.tsx` |
| `./src/components/music-player/VolumeControl.tsx` |
| `./src/components/music-player/RhythmPlaybackControls.tsx` |
| `./src/components/music-player/RhythmEditorControls.tsx` |
| `./src/components/music-player/PlaylistSheet.tsx` |
| `./src/components/music-player/PlaylistEditor.tsx` |
| `./src/components/music-player/PlaybackControls.tsx` |
| `./src/components/music-player/MusicPlayerDrawer.tsx` |
| `./src/components/music-player/ModeReorderList.tsx` |
| `./src/components/music-player/ErrorToast.tsx` |
| `./src/components/mobile/MobileReadingInterface.tsx` |
| `./src/components/loyalty/LoyaltyRewardNotification.tsx` |
| `./src/components/cards/__tests__/WastelandCard.test.tsx` |
| `./src/components/cards/WastelandStorySection.tsx` |
| `./src/components/cards/ResponsiveCardGrid.test.tsx` |
| `./src/components/cards/CardThumbnail.tsx` |
| `./src/components/cards/CardDetailModal.test.tsx` |
| `./src/components/bingo/RewardNotification.tsx` |
| `./src/components/audio/VolumeControl.tsx` |
| `./src/components/audio/VoiceSelector.tsx` |
| `./src/components/audio/SpeechControls.tsx` |
| `./src/components/audio/AudioControls.tsx` |
| `./src/app/test-tts/page.tsx` |
| `./src/app/test-tts-cloud/page.tsx` |
| `./src/app/test-streaming/page.tsx` |
| `./src/app/test-ai-interpretation/page.tsx` |
| `./src/app/share/[token]/page.tsx` |
| `./src/app/settings/page.tsx` |
| `./src/app/readings/new/page.tsx` |
| `./src/app/readings/[id]/page.tsx` |
| `./src/app/profile/page_tabs.tsx` |
| `./src/app/profile/page.tsx.backup` |
| `./src/app/profile/page.tsx` |
| `./src/app/cards/[suit]/[cardId]/page.tsx` |
| `./src/app/admin/interpretations/page.tsx` |
| `./src/app/admin/factions/page.tsx` |
| `./src/app/admin/faction-characters/page.tsx` |
| `./src/app/admin/characters/page.tsx` |
| `./package.json` |
| `./bun.lock` |
| `./backend/tests/conftest.py` |
| `./backend/app/services/user_service.py` |
| `./backend/app/services/user_preferences_service.py` |
| `./backend/app/services/session_service.py` |
| `./backend/app/services/async_user_analytics_service.py` |
| `./backend/app/services/async_recommendation_engine.py` |
| `./backend/app/services/achievement_checker.py` |
| `./backend/app/schemas/spreads.py` |
| `./backend/app/schemas/sessions.py` |
| `./backend/app/schemas/readings.py` |
| `./backend/app/models/reading_enhanced.py` |
| `./backend/app/main.py` |
| `./backend/app/db/seeds/character_faction_seeds.py` |
| `./backend/app/config.py` |
| `./backend/app/api/v1/endpoints/readings_stream.py` |
| `./backend/app/api/v1/endpoints/readings.py` |
| `./backend/app/api/v1/endpoints/preferences.py` |
| `./backend/app/api/v1/endpoints/cards.py` |
| `./backend/app/api/v1/endpoints/analytics.py` |
| `./backend/app/api/v1/api.py` |
| `./backend/alembic/versions/85d8d71873ae_add_interpretation_audio_url_to_.py` |
| `./backend/alembic/versions/5a51727110a2_merge_reading_journals_and_audio_url_.py` |
| `./CLAUDE.md` |
| `./src/lib/factionVoiceMapping.ts` |
| `./backend/app/schemas/cards.py` |
| `./backend/app/models/wasteland_card.py` |
| `./backend/app/core/faction_voice_mapping.py` |
| `./src/utils/speechHandler.ts` |
| `./src/types/character-voice.ts` |
| `./src/components/ui/icons/iconMetadata.ts` |
| `./src/lib/audio/SpeechEngine.ts` |
| `./src/lib/stores/musicPlayerStore.ts` |
| `./src/types/music.ts` |
| `./src/types/__tests__/api.test.ts` |
| `./src/lib/audio/PerformanceMonitor.ts` |
| `./src/lib/audio/drums/KickDrum.ts` |
| `./src/lib/audio/drums/DrumPatternEngine.ts` |
| `./src/lib/audio/drums/SnareDrum.ts` |
| `./src/lib/utils/__tests__/cardImages.test.ts` |
| `./src/hooks/audio/__tests__/useAudioInitialization.test.tsx` |
| `./src/app/cards/__tests__/page.test.tsx` |
| `./src/hooks/audio/useAudioKeyboard.ts` |
| `./src/hooks/audio/__tests__/useTextToSpeech.test.tsx` |
| `./src/lib/audio/AudioEngine.ts` |
| `./src/lib/audio/drums/HiHat.ts` |
| `./src/hooks/audio/__tests__/useAudioEffect.test.tsx` |
| `./src/hooks/audio/useRhythmMusicEngine.ts` |
| `./src/hooks/audio/useMusicEngine.ts` |
| `./src/lib/audio/drums/NoiseGenerator.ts` |
| `./src/hooks/audio/__tests__/useBackgroundMusic.test.tsx` |
| `./src/hooks/audio/useAudioInitialization.ts` |
| `./src/hooks/__tests__/useStreamingText.audio.test.ts` |
| `./src/hooks/audio/useVisibilityControl.ts` |
| `./src/hooks/audio/usePrefersReducedMotion.ts` |
| `./src/hooks/audio/usePerformanceMonitoring.ts` |
| `./src/hooks/audio/useTextToSpeech.ts` |
| `./src/hooks/audio/useAudioEffect.ts` |
| `./src/lib/audio/synthesizers/PadSynthesizer.ts` |
| `./src/hooks/audio/useBackgroundMusic.ts` |
| `./src/lib/audio/synthesizers/LeadSynthesizer.ts` |
| `./src/hooks/useKeyboardShortcuts.ts` |
| `./src/components/system/MusicPlayerInitializer.tsx` |
| `./src/hooks/useMusicPlayerInitializer.ts` |
| `./src/lib/audio/synthesizers/BassSynthesizer.ts` |
| `./src/lib/audio/synthesizers/ADSREnvelope.ts` |
| `./src/lib/audio/waveformAnalyzer.ts` |
| `./src/lib/audio/VoiceSelector.ts` |
| `./src/lib/audio/MusicManager.ts` |
| `./src/hooks/useMusicPlayer.ts` |
| `./src/hooks/useStreamingText.ts` |
| `./src/lib/audio/types.ts` |
| `./src/hooks/useAnalytics.ts` |
| `./src/components/audio/AudioVisualizer.tsx` |
| `./src/lib/audio/AudioErrorHandler.ts` |
| `./src/lib/audio/SoundGenerator.ts` |
| `./src/lib/audio/__tests__/audioStore.music.test.ts` |
| `./src/lib/audio/__tests__/RhythmAudioSynthesizer.test.ts` |
| `./src/components/audio/SoundEffectTrigger.tsx` |
| `./src/lib/audio/__tests__/SoundGenerator.test.ts` |
| `./src/lib/audio/__tests__/SpeechEngine.test.ts` |
| `./src/lib/audio/__tests__/audio-error-handling.test.ts` |
| `./src/lib/audio/__tests__/errorHandler.integration.test.ts` |
| `./src/lib/audio/__tests__/sound-config.test.ts` |
| `./src/hooks/useTextToSpeech.tsx` |
| `./src/__tests__/e2e/audio-initialization.audio.e2e.ts` |
| `./src/components/audio/__tests__/SpeechControls.test.tsx` |
| `./src/components/audio/__tests__/AudioControls.test.tsx` |
| `./src/components/audio/__tests__/AudioVisualizer.test.tsx` |
| `./src/lib/audio/__tests__/AudioEngine.test.ts` |
| `./src/__tests__/e2e/volume-control.audio.e2e.ts` |
| `./src/components/audio/AudioSettings.tsx` |
| `./src/__tests__/integration/error-handling.test.ts` |
| `./src/__tests__/e2e/sound-effects.audio.e2e.ts` |
| `./src/__tests__/integration/audio-system.test.ts` |
| `./src/lib/audio/__tests__/EditorAudioSynthesizer.test.ts` |
| `./src/lib/sessionStore.ts` |
| `./src/__tests__/e2e/background-music.audio.e2e.ts` |
| `./src/components/__tests__/integration/CardTiltIntegration.test.tsx` |
| `./src/lib/audio/__tests__/ProceduralMusicEngine.crossfade.test.ts` |
| `./src/lib/audio/__tests__/VolumeController.test.ts` |
| `./src/lib/audio/__tests__/AudioErrorHandler.test.ts` |
| `./src/__tests__/e2e/accessibility.audio.e2e.ts` |
| `./src/lib/audio/__tests__/MusicGenerator.test.ts` |
| `./src/lib/audio/__tests__/web-audio-integration.test.ts` |
| `./src/lib/webSpeechApi.ts` |
| `./src/lib/audio/__tests__/audioStore.smoke.test.ts` |
| `./src/lib/lazyComponents.tsx` |
| `./src/lib/audio/constants.ts` |
| `./src/lib/audio/EditorAudioSynthesizer.ts` |
| `./src/components/music-player/MusicModeSelector.tsx` |
| `./src/components/music-player/__tests__/PlaybackControls.test.tsx` |
| `./src/components/music-player/__tests__/MusicModeSelector.test.tsx` |
| `./src/components/music-player/__tests__/VolumeControl.test.tsx` |
| `./src/lib/audio/VolumeController.ts` |
| `./src/components/music-player/__tests__/MusicPlayerDrawer.integration.test.tsx` |
| `./src/components/tarot/TarotCard.tsx` |
| `./src/components/music-player/__tests__/PlaylistSheet.integration.test.tsx` |
| `./src/lib/audio/index.ts` |
| `./src/components/tarot/__tests__/StorySection.test.tsx` |
| `./src/lib/audio/AudioManager.ts` |
| `./src/components/tarot/__tests__/CharacterVoiceSelector.test.tsx` |
| `./src/lib/audio/effects/GatedReverb.ts` |
| `./src/lib/audio/effects/Chorus.ts` |
| `./src/lib/audio/effects/PingPongDelay.ts` |
| `./src/components/tarot/__tests__/StoryAudioPlayer.test.tsx` |
| `./src/lib/audio/effects/BitCrusher.ts` |
| `./src/components/analytics/RecommendationCard.tsx` |
| `./src/lib/audio/effects/PitchWarble.ts` |
| `./src/lib/audio/effects/EffectChain.ts` |
| `./src/lib/audio/effects/index.ts` |
| `./src/lib/audio/effects/TapeSaturation.ts` |
| `./src/lib/audio/audioStore.ts` |
| `./src/components/analytics/AnalyticsDashboard.tsx` |
| `./src/lib/audio/MusicGenerator.ts` |
| `./src/stores/__tests__/playlistStore.errors.test.ts` |
| `./src/lib/audio/EffectsProcessor.ts` |
| `./src/test/mocks/handlers/readings.ts` |
| `./src/stores/playlistStore.ts` |
| `./src/stores/__tests__/musicPlayerStore.test.ts` |
| `./src/test/mocks/handlers/users.ts` |
| `./src/stores/musicPlayerStore.ts` |
| `./src/lib/api/character-voice.ts` |
| `./src/lib/api/share.test.ts` |
| `./src/lib/api/sessions.ts` |
| `./src/data/voices.ts` |
| `./src/lib/analytics/tracker.ts` |
| `./backend/tests/unit/test_reading_journal_model.py` |
| `./backend/tests/unit/test_journal_service.py` |
| `./backend/tests/api/test_journal_endpoints.py` |
| `./backend/pytest.ini` |
| `./backend/pyproject.toml` |
| `./backend/uv.lock` |
| `./backend/app/api/v1/endpoints/social.py` |
| `./backend/app/api/v1/endpoints/share.py` |
| `./backend/scripts/execute_phase5_manual_test.py` |
| `./backend/app/services/ai_interpretation_service.py` |
| `./tests/e2e/achievement-system.spec.ts` |
| `./backend/tests/unit/test_share_service.py` |
| `./backend/tests/unit/test_add_share_token_migration.py` |
| `./backend/tests/api/test_share_api.py` |
| `./backend/app/services/share_service.py` |
| `./backend/migrate_story_audio.py` |
| `./backend/check_characters.py` |
| `./backend/tests/api/test_audio_story_endpoints.py` |
| `./backend/app/api/v1/endpoints/audio.py` |
| `./backend/app/schemas/audio.py` |
| `./backend/app/services/story_audio_service.py` |
| `./backend/tests/unit/test_story_audio_service.py` |
| `./backend/app/services/wasteland_card_service.py` |
| `./backend/tests/unit/test_story_schema.py` |
| `./backend/tests/unit/test_wasteland_card.py` |
| `./GOOGLE_CLOUD_TTS_SETUP.md` |
| `./backend/app/services/user_analytics_service.py` |
| `./backend/app/services/tts_service.py` |
| `./backend/app/services/recommendation_engine.py` |
| `./backend/app/services/reading_service.py` |
| `./backend/app/services/audio_storage_service.py` |
| `./backend/app/services/audio_cache_service.py` |
| `./backend/app/schemas/character_voice.py` |
| `./backend/app/models/user_analytics.py` |
| `./backend/app/models/character_voice.py` |
| `./backend/app/models/audio_file.py` |
| `./backend/app/api/v1/endpoints/test_ai.py` |
| `./backend/app/api/v1/endpoints/sessions.py` |
| `./backend/app/api/v1/endpoints/factions.py` |
| `./backend/app/api/v1/endpoints/characters.py` |
| `./backend/app/api/v1/endpoints/cards.py.backup` |
| `./backend/app/api/v1/endpoints/card_interpretations.py` |
| `./backend/alembic/versions/ceb36a9f99c5_add_character_voice_normalization_tables.py` |
| `./backend/alembic/versions/add_audio_files_table.py` |
| `./backend/app/db/spread_templates_seed.py` |
| `./backend/app/schemas/social.py` |
| `./backend/tests/unit/test_user_service.py` |
| `./backend/tests/factories.py` |
| `./src/lib/audio/README.md` |
| `./src/components/music-player/sample.html` |
| `./src/data/static-pages/faq.md` |
| `./backend/tests/music/conftest.py` |
| `./backend/supabase/migrations/001_create_music_tracks_table.sql` |
| `./backend/tests/music/test_api/test_playlist_endpoints.py` |
| `./backend/tests/music/test_database/test_migrations.py` |
| `./backend/tests/music/test_database/test_rls_policies.py` |
| `./backend/app/models/music/music_track.py` |
| `./supabase/migrations/20250111000000_create_music_tracks.sql` |
| `./tests/e2e/music-player-state-persistence.spec.ts` |
| `./tests/e2e/music-player-playback-flow.spec.ts` |
| `./src/components/music-player/README.md` |
| `./tests/e2e/audio-controls.spec.ts` |
| `./backend/app/services/analytics_service.py` |
| `./backend/alembic/versions/3118c80c0ade_sync_models_with_database_uuid_types.py` |
| `./src/lib/audio/drums/USAGE_EXAMPLE.md` |
| `./tests/mobile/MobileGestures.test.ts` |
| `./tests/e2e/critical-bugs-fix.spec.ts` |
| `./tests/accessibility/wcag-aa-compliance.spec.ts` |
| `./tests/accessibility/screen-reader-compatibility.spec.ts` |
| `./sql/validation_and_testing.sql` |
| `./sql/seed_wasteland_cards_structure.sql` |
| `./sql/optimized_wasteland_cards_schema.sql` |
| `./sql/migration_to_optimized_schema.sql` |
| `./sql/fix_database_structure.sql` |
| `./sql/execute_complete_fix.sql` |
| `./sql/enhanced_supabase_schema.sql` |
| `./sql/comprehensive_validation.sql` |
| `./sql/complete_78_cards_seed.sql` |
| `./playwright.audio.config.ts` |
| `./jest.audio.config.js` |
| `./docs/STREAMING_QUICK_REFERENCE.md` |
| `./docs/STREAMING_IMPLEMENTATION.md` |
| `./docs/07-information/fallout_tarot_algorithms.json` |
| `./docs/03-technical/fastapi-backend-development-plan.md` |
| `./docs/03-technical/architecture.md` |
| `./docs/03-technical/API.md` |
| `./docs/00-README.md` |
| `./cypress/support/types.ts` |
| `./cypress/support/e2e.ts` |
| `./cypress/support/commands.ts` |
| `./cypress/e2e/wasteland-tarot-core-flow.cy.ts` |
| `./cypress/e2e/reading-flow.cy.ts` |
| `./backend/tests/unit/test_wasteland_cards.py` |
| `./backend/tests/unit/test_user_models.py` |
| `./backend/tests/unit/test_swagger_localization.py` |
| `./backend/tests/unit/test_streaming.py` |
| `./backend/tests/unit/test_reading_service_advanced.py` |
| `./backend/tests/unit/test_karma_system.py` |
| `./backend/tests/unit/test_character_interpretation.py` |
| `./backend/tests/unit/test_ai_interpretation_service.py` |
| `./backend/tests/unit/test_ai_interpretation.py` |
| `./backend/tests/unit/test_advanced_card_drawing.py` |
| `./backend/tests/test_error_handling.py` |
| `./backend/tests/test_api_live.py` |
| `./backend/tests/test_api_endpoints_comprehensive.py` |
| `./backend/tests/performance/test_reading_performance.py` |
| `./backend/tests/performance/test_api_performance.py` |
| `./backend/tests/integration/test_wasteland_divination.py` |
| `./backend/tests/integration/test_user_management.py` |
| `./backend/tests/integration/test_user_api.py` |
| `./backend/tests/integration/test_streaming_api.py` |
| `./backend/tests/integration/test_reading_with_auth.py` |
| `./backend/tests/integration/test_personalization_engine.py` |
| `./backend/tests/integration/test_holotape_archive.py` |
| `./backend/tests/integration/test_end_to_end_workflows.py` |
| `./backend/tests/integration/test_complete_reading_flow.py` |
| `./backend/tests/edge_cases/test_fallout_theme_integrity.py` |
| `./backend/tests/api_comprehensive_test.py` |
| `./backend/tests/api/test_voices_endpoints.py` |
| `./backend/tests/api/test_updated_api_format.py` |
| `./backend/tests/api/test_streaming_endpoints.py` |
| `./backend/tests/api/test_readings_endpoints.py` |
| `./backend/tests/api/test_reading_analytics.py` |
| `./backend/tests/api/test_error_handling.py` |
| `./backend/tests/api/test_cards_endpoints.py` |
| `./backend/requirements-test.txt` |
| `./backend/app/services/reading_enhanced_service.py` |
| `./backend/app/schemas/voices.py` |
| `./backend/app/db/master_seed.py` |
| `./backend/app/db/interpretation_templates_seed.py` |
| `./backend/app/db/full_wasteland_seed.py` |
| `./backend/app/db/complete_wasteland_seed.py` |
| `./backend/app/api/v1/endpoints/voices.py` |
| `./backend/app/api/readings_enhanced.py` |
| `./backend/app/api/readings.py` |
| `./backend/app/api/cards.py` |
| `./backend/SUPABASE_SETUP.md` |
| `./backend/API_README.md` |
| `./backend/AI_SETUP_GUIDE.md` |
| `./backend/AI_QUICK_START.md` |
| `./backend/AI_INTERPRETATION_EXAMPLES.md` |
| `./AUDIO_SYSTEM_README.md` |
| `./tests/e2e/quick-reading.spec.ts` |
| `./docs/audio-system-web-audio-migration.md` |


</details>

---

<think><details><summary>Thought Process</summary>I can see there's already extensive TTS/audio functionality in the codebase. Let me look at some key files to understand the current TTS implementation.</details></think>

---

Tool use: **read_file**

Read file: src/app/test-tts/page.tsx

---

<think><details><summary>Thought Process</summary>I can see there's already a comprehensive TTS system using the browser's built-in Web Speech API. Let me also check the test-tts-cloud page to see if there's already some cloud TTS implementation.</details></think>

---

Tool use: **read_file**

Read file: src/app/test-tts-cloud/page.tsx

---

<think><details><summary>Thought Process</summary>Now I can see there's already a Google Cloud TTS implementation that calls `/api/v1/audio/synthesize`. Let me check the backend API to understand the current implementation.</details></think>

---

Tool use: **read_file**

Read file: backend/app/api/v1/endpoints/audio.py

---

<think><details><summary>Thought Process</summary>Now I can see the current TTS implementation uses Google Cloud TTS. Let me check the TTS service to understand the current implementation.</details></think>

---

Tool use: **grep**

<details>
<summary>Grep for "class TTSService|def synthesize_speech" â€¢ 1 match</summary>

Output mode: files_with_matches


| File |
|------|
| `./backend/app/services/tts_service.py` |


</details>

---

<think><details><summary>Thought Process</summary>Let me read the TTS service to understand the current implementation.</details></think>

---

Tool use: **read_file**

Read file: backend/app/services/tts_service.py

---

<think><details><summary>Thought Process</summary>Now I have a complete understanding of the current TTS implementation. The system already uses Google Cloud TTS, but it's using the older WaveNet voices. The user wants to implement Chirp 3:HD, which is Google's latest and most advanced TTS model.


## Reviewing TTS Implementation  
- The current system relies on Google Cloud TTS with older WaveNet voices for text-to-speech conversion.  
- The user aims to upgrade to Chirp 3:HD, Google's latest and most advanced TTS model, for enhanced audio quality.</details></think>

---

Tool use: **run_terminal_cmd**

```bash
date -u +"%Y-%m-%dT%H:%M:%SZ"
```

```
2025-11-03T16:20:08Z

```

---

<think><details><summary>Thought Process</summary>Now I'll update the spec.json to mark requirements as generated and ready for review, then create comprehensive requirements.</details></think>

---

Tool use: **search_replace**


<details><summary>Edit file: .kiro/specs/chirp3-hd-tts-system/spec.json</summary>

**Chunk 1**
Lines added: 3, lines removed: 3

```diff
@@ -2,10 +2,10 @@
    "feature_name": "chirp3-hd-tts-system",
    "created_at": "2025-11-03T16:19:08Z",
-   "updated_at": "2025-11-03T16:19:08Z",
+   "updated_at": "2025-11-03T16:20:08Z",
    "language": "en",
-   "phase": "initialized",
+   "phase": "requirements_generated",
    "approvals": {
      "requirements": {
-       "generated": false,
+       "generated": true,
        "approved": false
      },
```

</details>

---

<think><details><summary>Thought Process</summary>Now I need to create comprehensive requirements for the Chirp 3:HD TTS system implementation. Based on my analysis of the current system and the Chirp 3:HD documentation, I need to write detailed requirements covering:
</details></think>

---

Tool use: **search_replace**


<details><summary>Edit file: .kiro/specs/chirp3-hd-tts-system/requirements.md</summary>

**Chunk 1**
Lines added: 266, lines removed: 1

```diff
@@ -5,4 +5,269 @@
  
  ## Requirements
- <!-- Will be generated in /kiro:spec-requirements phase -->
...
+ ### 1. Voice Model Upgrade
+ **Priority: Critical**
+ 
+ **Description:**
+ Upgrade the existing Google Cloud TTS implementation from WaveNet voices to the latest Chirp 3:HD model for significantly improved audio quality and emotional expression.
+ 
+ **Requirements:**
+ - Replace all WaveNet voice mappings with Chirp 3:HD equivalents
+ - Ensure backward compatibility with existing 14 Fallout character voices
+ - Maintain current voice personality characteristics (pitch, rate, volume)
+ - Implement proper fallback mechanisms for unsupported voice features
+ 
+ **Success Criteria:**
+ - All existing character voices successfully mapped to Chirp 3:HD voices
+ - Audio quality improvements are perceptible and positive
+ - No breaking changes to existing API contracts
+ 
+ ### 2. Chirp 3:HD Voice Mapping
+ **Priority: High**
+ 
+ **Description:**
+ Map existing Fallout characters to appropriate Chirp 3:HD voices based on gender, personality, and vocal characteristics.
+ 
+ **Current Character Analysis:**
+ - **Low-pitch male voices**: super_mutant, brotherhood_paladin, legion_centurion (need deep, authoritative voices)
+ - **Mid-pitch male voices**: ghoul, wasteland_trader, ncr_ranger, pip_boy, minuteman (need mature, professional tones)
+ - **High-pitch female voices**: vault_dweller, railroad_agent, brotherhood_scribe (need youthful, intelligent voices)
+ - **Special voices**: codsworth (robotic), raider (rough), institute_scientist (analytical)
+ 
+ **Requirements:**
+ - Research and select optimal Chirp 3:HD voice names for each character
+ - Document voice selection rationale based on character personality
+ - Create mapping configuration that preserves existing voice parameters
+ - Support voice switching for different language requirements
+ 
+ **Success Criteria:**
+ - Each character has a designated Chirp 3:HD voice
+ - Voice selections enhance rather than detract from character personalities
+ - Documentation explains voice selection decisions
+ 
+ ### 3. Custom Pronunciation Support
+ **Priority: High**
+ 
+ **Description:**
+ Implement support for custom pronunciations using IPA phonetic encoding, allowing precise control over difficult words, names, and technical terms.
+ 
+ **Requirements:**
+ - Add IPA phonetic encoding support to TTS service
+ - Implement pronunciation override mechanisms
+ - Support both inline pronunciation hints and global pronunciation dictionaries
+ - Integrate with existing SSML generation system
+ 
+ **Technical Implementation:**
+ - Extend `synthesize_speech` method to accept pronunciation parameters
+ - Add `custom_pronunciations` field to API requests
+ - Support IPA phonetic encoding as documented in Chirp 3:HD specs
+ - Implement fallback for unsupported languages
+ 
+ **Success Criteria:**
+ - Ability to specify custom pronunciations for proper nouns
+ - Pronunciation overrides work with existing caching system
+ - No performance impact on standard synthesis requests
+ 
+ ### 4. Voice Control Features
+ **Priority: Medium**
+ 
+ **Description:**
+ Implement advanced voice control features including speed adjustment, pitch modulation, and pause controls as supported by Chirp 3:HD.
+ 
+ **Requirements:**
+ - **Speed Control**: Support speaking rate adjustments (0.25x to 4.0x)
+ - **Pitch Control**: Support pitch adjustments (-20 to +20 semitones)
+ - **Pause Control**: Support custom pause lengths for dramatic effect
+ - **Volume Control**: Maintain existing volume controls
+ 
+ **API Extensions:**
+ - Extend voice configuration to include new control parameters
+ - Add validation for parameter ranges
+ - Implement parameter inheritance from character defaults
+ - Support runtime parameter overrides
+ 
+ **Success Criteria:**
+ - All voice control parameters work within Chirp 3:HD supported ranges
+ - Parameters integrate seamlessly with existing SSML generation
+ - Voice controls enhance dramatic reading capabilities
+ 
+ ### 5. Multi-Language Support
+ **Priority: Medium**
+ 
+ **Description:**
+ Ensure Chirp 3:HD implementation supports the current multi-language requirements while leveraging the model's language capabilities.
+ 
+ **Current Languages:**
+ - Primary: Traditional Chinese (zh-TW)
+ - Secondary: Simplified Chinese (zh-CN), English (en-US)
+ - Potential: Additional languages supported by Chirp 3:HD
+ 
+ **Requirements:**
+ - Verify Chirp 3:HD support for existing languages
+ - Update language code mappings for Chirp 3:HD voices
+ - Maintain backward compatibility with existing language parameters
+ - Implement proper language-specific voice selection
+ 
+ **Success Criteria:**
+ - All existing languages work with Chirp 3:HD
+ - Language switching preserves character voice characteristics
+ - No regression in language support quality
+ 
+ ### 6. Audio Quality and Performance
+ **Priority: High**
+ 
+ **Description:**
+ Leverage Chirp 3:HD's high-definition audio capabilities and optimize performance for the tarot reading use case.
+ 
+ **Requirements:**
+ - **HD Audio Output**: Utilize highest quality audio encoding supported
+ - **Performance Optimization**: Ensure synthesis speed meets real-time reading requirements
+ - **File Size Management**: Optimize audio file sizes for web delivery
+ - **Caching Efficiency**: Update caching strategy for new voice parameters
+ 
+ **Technical Specifications:**
+ - Target synthesis time: < 2 seconds for typical tarot readings
+ - Audio format: MP3 or WAV with optimal quality settings
+ - File size targets: Maintain reasonable sizes for web playback
+ - Caching hit rate: > 90% for repeated readings
+ 
+ **Success Criteria:**
+ - Audio quality noticeably improved over WaveNet
+ - Synthesis performance meets user experience requirements
+ - File sizes remain manageable for web delivery
+ 
+ ### 7. Backward Compatibility
+ **Priority: Critical**
+ 
+ **Description:**
+ Ensure the Chirp 3:HD upgrade doesn't break existing functionality or API contracts.
+ 
+ **Requirements:**
+ - **API Compatibility**: Maintain existing API endpoints and request/response formats
+ - **Character Mapping**: Preserve all 14 existing character voice configurations
+ - **Caching Compatibility**: Existing cached audio remains valid where possible
+ - **Fallback Mechanisms**: Implement graceful degradation if Chirp 3:HD unavailable
+ 
+ **Migration Strategy:**
+ - Phase 1: Add Chirp 3:HD alongside WaveNet (dual support)
+ - Phase 2: Gradually migrate characters to Chirp 3:HD voices
+ - Phase 3: Remove WaveNet support after full testing
+ - Rollback capability if issues discovered
+ 
+ **Success Criteria:**
+ - No breaking changes to existing API consumers
+ - Existing cached audio continues to work
+ - Smooth migration path with rollback capability
+ 
+ ### 8. Caching Strategy Updates
+ **Priority: Medium**
+ 
+ **Description:**
+ Update the existing Redis/database caching system to handle Chirp 3:HD voice parameters and ensure efficient cache utilization.
+ 
+ **Current Caching:**
+ - Redis for fast access (5-minute TTL)
+ - Database for persistent storage
+ - Text hash-based cache keys
+ - Character-specific caching
+ 
+ **Requirements:**
+ - **Cache Key Updates**: Include voice model version in cache keys
+ - **Parameter Hashing**: Include pronunciation and voice control parameters in hash
+ - **Migration Handling**: Handle cache invalidation during voice model transition
+ - **Performance Monitoring**: Track cache hit rates and synthesis performance
+ 
+ **Success Criteria:**
+ - Cache hit rates maintained or improved
+ - No cache pollution from model transition
+ - Efficient storage utilization
+ 
+ ### 9. Testing and Quality Assurance
+ **Priority: High**
+ 
+ **Description:**
+ Comprehensive testing to ensure Chirp 3:HD implementation meets quality standards and doesn't introduce regressions.
+ 
+ **Testing Requirements:**
+ - **Unit Tests**: TTS service methods with Chirp 3:HD parameters
+ - **Integration Tests**: Full API request/response cycles
+ - **Audio Quality Tests**: Subjective and objective audio quality assessments
+ - **Performance Tests**: Synthesis speed and resource utilization
+ - **Compatibility Tests**: Backward compatibility verification
+ 
+ **Test Characters:**
+ - All 14 Fallout characters must pass audio synthesis tests
+ - Sample tarot reading texts in multiple languages
+ - Edge cases: long texts, special characters, empty inputs
+ 
+ **Success Criteria:**
+ - All existing tests pass
+ - New Chirp 3:HD functionality fully tested
+ - Audio quality approved by stakeholders
+ - Performance benchmarks met
+ 
+ ### 10. Documentation and Monitoring
+ **Priority: Medium**
+ 
+ **Description:**
+ Update documentation and add monitoring capabilities for the Chirp 3:HD implementation.
+ 
+ **Requirements:**
+ - **API Documentation**: Update TTS service documentation for new features
+ - **Voice Mapping Documentation**: Document character-to-voice mappings and rationale
+ - **Configuration Guide**: Instructions for voice parameter tuning
+ - **Monitoring**: Add metrics for synthesis performance and quality
+ 
+ **Monitoring Requirements:**
+ - Synthesis success/failure rates
+ - Average synthesis time by character/voice
+ - Cache hit rates and performance
+ - Audio file size distributions
+ - Error rates and types
+ 
+ **Success Criteria:**
+ - Complete documentation for new features
+ - Monitoring dashboards show system health
+ - Troubleshooting guides available
+ 
+ ### 11. Deployment and Rollout
+ **Priority: Medium**
+ 
+ **Description:**
+ Safe deployment strategy with phased rollout and rollback capabilities.
+ 
+ **Requirements:**
+ - **Feature Flags**: Ability to enable/disable Chirp 3:HD per character or globally
+ - **Gradual Rollout**: Percentage-based rollout with monitoring
+ - **Rollback Plan**: Immediate rollback capability if issues detected
+ - **Resource Planning**: Ensure sufficient Google Cloud TTS quotas
+ 
+ **Success Criteria:**
+ - Zero-downtime deployment
+ - Gradual rollout allows for issue detection
+ - Quick rollback capability
+ - Resource usage within planned limits
+ 
+ ## Acceptance Criteria
+ 
+ ### Functional Requirements
+ - âœ… All 14 Fallout characters successfully mapped to Chirp 3:HD voices
+ - âœ… Custom pronunciation support implemented and tested
+ - âœ… Voice control features (speed, pitch, pauses) working
+ - âœ… Multi-language support maintained
+ - âœ… Audio quality improved over WaveNet baseline
+ - âœ… Backward compatibility preserved
+ 
+ ### Non-Functional Requirements
+ - âœ… Synthesis performance < 2 seconds for typical readings
+ - âœ… Cache hit rate > 90%
+ - âœ… API response times maintained
+ - âœ… No breaking changes to existing contracts
+ - âœ… Comprehensive test coverage > 95%
+ 
+ ### Quality Requirements
+ - âœ… Audio quality subjectively better than WaveNet
+ - âœ… Voice personalities preserved and enhanced
+ - âœ… Error handling robust and user-friendly
+ - âœ… Documentation complete and accurate
+ 
```

</details>

---

<think><details><summary>Thought Process</summary>Now I need to create a todo list to track the requirements generation task completion, and then provide the output as specified in the instructions.</details></think>

---

Tool use: **todo_write**

## Todo List

- [x] Generate comprehensive requirements for Chirp 3:HD TTS system implementation

---

<think><details><summary>Thought Process</summary>Perfect! Now I need to provide the output in the specified format. Since the spec.json language is "en", but the user rules specify Traditional Chinese, and this is a response to the user, I should respond in Traditional Chinese as per the user rules.

Since there is no ExistingSummary and the NewReasoningContent provides new reasoning, I'll start with a fresh subheading.

## Determining response language  
- The spec.</details></think>

---

ğŸ¤–

## ç”¢ç”Ÿçš„åŠŸèƒ½åç¨±
`chirp3-hd-tts-system` - é€™æ˜¯åŸºæ–¼å°ˆæ¡ˆæè¿°ã€Œå¯¦ä½œ TTS ç³»çµ±ä½¿ç”¨ Google Chirp 3ï¼šHD æ¨¡å‹ã€æ‰€ç”¢ç”Ÿçš„åŠŸèƒ½åç¨±ï¼Œæº–ç¢ºåæ˜ äº†å¾ç¾æœ‰ WaveNet èªéŸ³å‡ç´šåˆ°æœ€æ–° Chirp 3ï¼šHD æ¨¡å‹çš„æ ¸å¿ƒéœ€æ±‚ã€‚

## å°ˆæ¡ˆæ‘˜è¦
å¯¦ä½œåŸºæ–¼ Google Cloud Chirp 3ï¼šHD æ¨¡å‹çš„é€²éšæ–‡å­—è½‰èªéŸ³ç³»çµ±ï¼Œæ›¿æ›ç¾æœ‰çš„ WaveNet èªéŸ³ä»¥æå‡éŸ³è³ªå’Œæƒ…æ„Ÿè¡¨é”ã€‚

## å»ºç«‹çš„æª”æ¡ˆ
- `.kiro/specs/chirp3-hd-tts-system/spec.json`
- `.kiro/specs/chirp3-hd-tts-system/requirements.md`

## ä¸‹ä¸€æ­¥
```bash
/kiro:spec-design chirp3-hd-tts-system
```

## å‚™è¨»
å·²å®Œæˆéœ€æ±‚åˆ†æéšæ®µï¼Œè©³ç´°åˆ†æäº†ç¾æœ‰ TTS ç³»çµ±æ¶æ§‹ï¼ˆåŒ…å« 14 å€‹ Fallout è§’è‰²èªéŸ³æ˜ å°„ã€å¿«å–ç­–ç•¥ã€API ç«¯é»ï¼‰ï¼Œä¸¦æ ¹æ“š Chirp 3ï¼šHD çš„æŠ€è¡“è¦ç¯„åˆ¶å®šäº† 11 é …æ ¸å¿ƒéœ€æ±‚ï¼Œæ¶µè“‹èªéŸ³æ¨¡å‹å‡ç´šã€è‡ªè¨‚ç™¼éŸ³æ”¯æ´ã€èªéŸ³æ§åˆ¶åŠŸèƒ½ã€å¤šèªè¨€æ”¯æ´ã€å‘å¾Œç›¸å®¹æ€§ã€æ¸¬è©¦ç­–ç•¥ç­‰é¢å‘ã€‚éœ€æ±‚æ–‡ä»¶å·²æº–å‚™å¥½ä¾›è¨­è¨ˆéšæ®µå¯©æ ¸ã€‚

---

_**User (2025-11-03 16:17Z)**_

/kiro:spec-design chirp3-hd-tts-system

---

_**Assistant (claude-4.5-sonnet)**_

Tool use: **read_file**

Read file: .kiro/specs/chirp3-hd-tts-system/spec.json

---

Tool use: **read_file**

Read file: .kiro/specs/chirp3-hd-tts-system/requirements.md

---

Tool use: **run_terminal_cmd**

```bash
date -u +"%Y-%m-%dT%H:%M:%SZ"
```

```
2025-11-03T16:21:25Z

```

---

Tool use: **write**


<details><summary>Edit file: .kiro/specs/chirp3-hd-tts-system/design.md</summary>

**Chunk 1**
Lines added: 955, lines removed: 1

```diff
@@ -1,1 +1,955 @@
- 
+ # Technical Design Document
+ 
+ ## Overview
+ 
+ This document provides the technical design for upgrading the existing Google Cloud TTS system from WaveNet voices to Chirp 3:HD, Google's latest high-definition text-to-speech model. The design ensures backward compatibility, maintains voice personality characteristics, and leverages Chirp 3:HD's advanced features including custom pronunciations and enhanced voice controls.
+ 
+ ## Architecture Overview
+ 
+ ### System Context
+ 
+ ```
+ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
+ â”‚                        Frontend (Next.js)                        â”‚
+ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
+ â”‚  â”‚ TTS Test Pages â”‚  â”‚ Audio Controls â”‚  â”‚ Character Voice  â”‚  â”‚
+ â”‚  â”‚  (Web Speech)  â”‚  â”‚   Components   â”‚  â”‚    Selector      â”‚  â”‚
+ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
+ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
+                                  â”‚ HTTP/REST
+                                  â–¼
+ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
+ â”‚                      Backend API (FastAPI)                       â”‚
+ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
+ â”‚  â”‚              Audio API Endpoints                          â”‚  â”‚
+ â”‚  â”‚  - POST /api/v1/audio/synthesize (dynamic TTS)           â”‚  â”‚
+ â”‚  â”‚  - POST /api/v1/audio/generate/story (story audio)       â”‚  â”‚
+ â”‚  â”‚  - GET  /api/v1/audio/story/{card_id} (get URLs)         â”‚  â”‚
+ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
+ â”‚                                 â”‚                                â”‚
+ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
+ â”‚  â”‚         Service Layer        â”‚                           â”‚  â”‚
+ â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”‚
+ â”‚  â”‚  â”‚ Audio Storage     â”‚  â”‚   TTSService       â”‚â—„â”€â”€â”€â”€â”   â”‚  â”‚
+ â”‚  â”‚  â”‚ Service           â”‚  â”‚  (Chirp 3:HD)      â”‚     â”‚   â”‚  â”‚
+ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   â”‚  â”‚
+ â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚   â”‚  â”‚
+ â”‚  â”‚  â”‚ Audio Cache       â”‚  â”‚ Story Audio        â”‚     â”‚   â”‚  â”‚
+ â”‚  â”‚  â”‚ Service (Redis)   â”‚  â”‚ Service            â”‚â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
+ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”‚
+ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
+ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
+                                  â”‚
+                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
+                      â–¼           â–¼           â–¼
+               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
+               â”‚  Redis   â”‚ â”‚ Supabaseâ”‚ â”‚ Google   â”‚
+               â”‚  Cache   â”‚ â”‚ Storage â”‚ â”‚ Cloud    â”‚
+               â”‚          â”‚ â”‚  & DB   â”‚ â”‚ TTS API  â”‚
+               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
+ ```
+ 
+ ### Key Components
+ 
+ #### 1. TTSService (Backend)
+ **Location:** `backend/app/services/tts_service.py`
+ 
+ **Current Responsibilities:**
+ - Voice synthesis using Google Cloud TTS WaveNet
+ - SSML generation for voice modulation
+ - Voice parameter conversion (pitch, rate)
+ - Text hash computation for caching
+ - Character-to-voice mapping
+ 
+ **New Responsibilities (Chirp 3:HD):**
+ - Voice synthesis using Chirp 3:HD models
+ - Custom pronunciation support via IPA encoding
+ - Enhanced voice control features
+ - Dual model support (WaveNet fallback)
+ - Voice model version management
+ 
+ #### 2. Audio API Endpoints
+ **Location:** `backend/app/api/v1/endpoints/audio.py`
+ 
+ **Current Endpoints:**
+ - `POST /api/v1/audio/synthesize` - Dynamic TTS synthesis
+ - `POST /api/v1/audio/generate/story` - Story audio generation
+ - `GET /api/v1/audio/story/{card_id}` - Get story audio URLs
+ 
+ **No changes required** - API contracts remain stable
+ 
+ #### 3. Caching System
+ **Components:**
+ - **Redis Cache:** Fast access layer (5-minute TTL)
+ - **Database Storage:** Persistent audio metadata
+ - **Supabase Storage:** Audio file storage
+ 
+ **Update Required:** Include voice model version in cache keys
+ 
+ ## Chirp 3:HD Voice Mapping
+ 
+ ### Voice Selection Strategy
+ 
+ Based on the Chirp 3:HD documentation, the available voice names follow the pattern:
+ - `en-US-Chirp3-HD-{VoiceName}` for English (US)
+ - Multiple voice options: Achernar, Achird, Algenib, etc.
+ 
+ For Traditional Chinese (zh-TW), we need to verify availability and potentially use:
+ - English voices with Chinese text (Chirp 3:HD supports cross-lingual)
+ - Or wait for official Chinese Chirp 3:HD voices
+ 
+ ### Character Voice Mapping Table
+ 
+ | Character Key         | Current (WaveNet)   | Chirp 3:HD Target        | Gender | Pitch  | Rate | Rationale                                    |
+ | --------------------- | ------------------- | ------------------------ | ------ | ------ | ---- | -------------------------------------------- |
+ | super_mutant          | cmn-TW-Wavenet-C    | en-US-Chirp3-HD-Algenib  | Male   | -12st  | 0.65 | Deep, powerful, authoritative                |
+ | brotherhood_paladin   | cmn-TW-Wavenet-C    | en-US-Chirp3-HD-Algieba  | Male   | -8st   | 0.75 | Military authority, commanding               |
+ | legion_centurion      | cmn-TW-Wavenet-C    | en-US-Chirp3-HD-Alnilam  | Male   | -10st  | 0.7  | Severe military discipline                   |
+ | ghoul                 | cmn-TW-Wavenet-B    | en-US-Chirp3-HD-Mizar    | Male   | -6st   | 0.8  | Weathered, experienced, gravelly             |
+ | wasteland_trader      | cmn-TW-Wavenet-B    | en-US-Chirp3-HD-Vega     | Male   | -4st   | 0.9  | Practical merchant, shrewd                   |
+ | ncr_ranger            | cmn-TW-Wavenet-B    | en-US-Chirp3-HD-Deneb    | Male   | -5st   | 0.85 | Professional soldier, calm                   |
+ | pip_boy               | cmn-TW-Wavenet-B    | en-US-Chirp3-HD-Regulus  | Male   | 0st    | 1.0  | Neutral AI assistant, friendly               |
+ | minuteman             | cmn-TW-Wavenet-B    | en-US-Chirp3-HD-Altair   | Male   | -2st   | 0.95 | Reliable civilian protector                  |
+ | vault_dweller         | cmn-TW-Wavenet-A    | en-US-Chirp3-HD-Aoede    | Female | +4st   | 1.1  | Young, optimistic, energetic                 |
+ | railroad_agent        | cmn-TW-Wavenet-A    | en-US-Chirp3-HD-Leda     | Female | +3st   | 1.15 | Quick-witted, secretive                      |
+ | brotherhood_scribe    | cmn-TW-Wavenet-A    | en-US-Chirp3-HD-Callisto | Female | +5st   | 1.05 | Intelligent scholar, curious                 |
+ | codsworth             | cmn-TW-Wavenet-B    | en-US-Chirp3-HD-Fomalhaut| Male   | +8st   | 1.25 | Robotic butler, precise, formal              |
+ | raider                | cmn-TW-Wavenet-B    | en-US-Chirp3-HD-Hadar    | Male   | -3st   | 1.3  | Aggressive, violent, unpredictable           |
+ | institute_scientist   | cmn-TW-Wavenet-A    | en-US-Chirp3-HD-Kore     | Female | +6st   | 1.15 | Analytical intellectual, detached            |
+ 
+ **Note:** Voice selections based on:
+ 1. **Gender matching:** Preserve existing gender associations
+ 2. **Tonal characteristics:** Match voice descriptions from Chirp 3:HD documentation
+ 3. **Personality fit:** Select voices that enhance character traits
+ 4. **Pitch/rate compatibility:** Ensure modulation parameters work well
+ 
+ ### Multi-Language Strategy
+ 
+ **Primary Language (zh-TW):**
+ - **Phase 1:** Use English Chirp 3:HD voices with Chinese text (cross-lingual support)
+ - **Phase 2:** Migrate to Chinese Chirp 3:HD voices when available
+ - **Fallback:** Retain WaveNet Chinese voices as backup
+ 
+ **Secondary Languages:**
+ - **zh-CN:** Same strategy as zh-TW
+ - **en-US:** Use native English Chirp 3:HD voices directly
+ 
+ ## Custom Pronunciation Support
+ 
+ ### Architecture
+ 
+ ```python
+ # New data structure for pronunciation overrides
+ class CustomPronunciation:
+     phrase: str              # Text to override (e.g., "Tarot", "Pip-Boy")
+     pronunciation: str       # IPA phonetic (e.g., "ËˆtÃ¦.roÊŠ", "pÉªp bÉ”Éª")
+     phonetic_encoding: str   # "PHONETIC_ENCODING_IPA"
+ 
+ class PronunciationDictionary:
+     """Global pronunciation dictionary for common terms"""
+     def __init__(self):
+         self.entries: Dict[str, CustomPronunciation] = {}
+     
+     def add_entry(self, phrase: str, ipa: str) -> None:
+         """Add pronunciation entry"""
+         pass
+     
+     def get_pronunciation(self, phrase: str) -> Optional[str]:
+         """Get IPA pronunciation for phrase"""
+         pass
+ ```
+ 
+ ### Integration Points
+ 
+ #### 1. API Request Schema Extension
+ 
+ ```python
+ # Extend SynthesizeRequest
+ class SynthesizeRequest(BaseModel):
+     text: str
+     character_key: str
+     audio_type: str = "ai_response"
+     cache_enabled: bool = True
+     return_format: str = "url"
+     
+     # NEW: Custom pronunciations
+     custom_pronunciations: Optional[List[CustomPronunciation]] = None
+ ```
+ 
+ #### 2. TTSService Methods
+ 
+ ```python
+ class TTSService:
+     def apply_custom_pronunciations(
+         self, 
+         text: str, 
+         pronunciations: List[CustomPronunciation]
+     ) -> str:
+         """
+         Apply custom pronunciations to text using markup
+         
+         Returns:
+             Marked-up text for Chirp 3:HD
+             Example: "I read [custom:rÉ›d] this book"
+         """
+         pass
+     
+     def generate_chirp3_input(
+         self, 
+         text: str,
+         character_key: str,
+         custom_pronunciations: Optional[List[CustomPronunciation]] = None
+     ) -> texttospeech.SynthesisInput:
+         """
+         Generate Chirp 3:HD synthesis input with pronunciations
+         
+         Uses custom_pronunciations field in SynthesisInput
+         """
+         pass
+ ```
+ 
+ ### Example Usage
+ 
+ ```python
+ # Request with custom pronunciation
+ request = {
+     "text": "Pip-Boy 3000 æ˜¯å»¢åœŸç”Ÿå­˜å¿…å‚™å·¥å…·",
+     "character_key": "pip_boy",
+     "custom_pronunciations": [
+         {
+             "phrase": "Pip-Boy",
+             "pronunciation": "pÉªp bÉ”Éª",
+             "phonetic_encoding": "PHONETIC_ENCODING_IPA"
+         }
+     ]
+ }
+ ```
+ 
+ ## Voice Control Features
+ 
+ ### Enhanced SSML Generation
+ 
+ #### Current Implementation
+ ```python
+ def generate_ssml(self, text: str, character_key: str) -> str:
+     pitch, rate = self.convert_voice_params(character_key)
+     return f"""<speak>
+   <prosody pitch="{pitch:+.1f}st" rate="{rate:.2f}">
+     {text}
+   </prosody>
+ </speak>"""
+ ```
+ 
+ #### Enhanced Implementation (Chirp 3:HD)
+ 
+ ```python
+ class VoiceControlParams(BaseModel):
+     """Voice control parameters"""
+     pitch: Optional[float] = None      # -20 to +20 semitones
+     rate: Optional[float] = None       # 0.25 to 4.0
+     volume: Optional[float] = None     # 0.0 to 1.0
+     pauses: Optional[List[Pause]] = None  # Custom pause positions
+ 
+ class Pause(BaseModel):
+     """Pause control"""
+     position: int          # Character position in text
+     duration: str         # "short" | "medium" | "long" | "500ms"
+ 
+ def generate_chirp3_markup(
+     self,
+     text: str,
+     character_key: str,
+     voice_controls: Optional[VoiceControlParams] = None
+ ) -> str:
+     """
+     Generate Chirp 3:HD markup with enhanced controls
+     
+     Supports:
+     - Character-default voice parameters
+     - Runtime voice control overrides
+     - Custom pause insertion
+     - Speed/pitch modulation
+     """
+     # Get character defaults
+     defaults = self.get_voice_config(character_key)
+     
+     # Apply overrides
+     pitch = voice_controls.pitch if voice_controls else defaults["pitch"]
+     rate = voice_controls.rate if voice_controls else defaults["rate"]
+     
+     # Insert pauses if specified
+     marked_text = self._insert_pauses(text, voice_controls.pauses)
+     
+     # Generate markup
+     return f"""
+ {marked_text}
+ [pace {rate:.2f}]
+ [pitch {pitch:+.1f}st]
+ """
+ ```
+ 
+ ### Pause Control Implementation
+ 
+ ```python
+ def _insert_pauses(self, text: str, pauses: Optional[List[Pause]]) -> str:
+     """
+     Insert pause markers into text
+     
+     Example:
+         Input:  "Hello [pause:500ms] World"
+         Output: "Hello [pause long] World"
+     """
+     if not pauses:
+         return text
+     
+     # Sort pauses by position (descending)
+     sorted_pauses = sorted(pauses, key=lambda p: p.position, reverse=True)
+     
+     result = text
+     for pause in sorted_pauses:
+         marker = f"[pause {pause.duration}]"
+         result = result[:pause.position] + marker + result[pause.position:]
+     
+     return result
+ ```
+ 
+ ## Caching Strategy
+ 
+ ### Cache Key Design
+ 
+ #### Current Cache Key
+ ```python
+ text_hash = hashlib.sha256(f"{text}:{character_key}".encode()).hexdigest()
+ ```
+ 
+ #### Enhanced Cache Key (Chirp 3:HD)
+ ```python
+ def compute_cache_key(
+     text: str,
+     character_key: str,
+     voice_model: str = "chirp3-hd",
+     custom_pronunciations: Optional[List[CustomPronunciation]] = None,
+     voice_controls: Optional[VoiceControlParams] = None
+ ) -> str:
+     """
+     Compute cache key including all synthesis parameters
+     
+     Format: SHA256(text:character:model:pronunciations:controls)
+     """
+     components = [text, character_key, voice_model]
+     
+     # Include pronunciations if present
+     if custom_pronunciations:
+         pron_str = "|".join(
+             f"{p.phrase}:{p.pronunciation}" 
+             for p in sorted(custom_pronunciations, key=lambda x: x.phrase)
+         )
+         components.append(pron_str)
+     
+     # Include voice controls if present
+     if voice_controls:
+         ctrl_str = f"p{voice_controls.pitch}r{voice_controls.rate}"
+         components.append(ctrl_str)
+     
+     cache_input = ":".join(components)
+     return hashlib.sha256(cache_input.encode()).hexdigest()
+ ```
+ 
+ ### Cache Migration Strategy
+ 
+ #### Phase 1: Dual Caching
+ - Maintain separate cache namespaces: `tts:wavenet:*` and `tts:chirp3:*`
+ - Allow parallel operation during transition
+ - No cache invalidation required
+ 
+ #### Phase 2: Gradual Migration
+ - New requests use Chirp 3:HD cache
+ - Old WaveNet cache entries expire naturally (5-minute TTL)
+ - Monitor cache hit rates per model
+ 
+ #### Phase 3: Cleanup
+ - Remove WaveNet cache namespace after full migration
+ - Update cache monitoring dashboards
+ 
+ ## Feature Flags and Rollout
+ 
+ ### Configuration System
+ 
+ ```python
+ # New configuration in app/config.py
+ class Settings(BaseSettings):
+     # Existing settings...
+     
+     # NEW: Chirp 3:HD feature flags
+     chirp3_enabled: bool = Field(
+         default=False,
+         env="CHIRP3_ENABLED",
+         description="Enable Chirp 3:HD globally"
+     )
+     
+     chirp3_rollout_percentage: int = Field(
+         default=0,
+         env="CHIRP3_ROLLOUT_PERCENTAGE",
+         description="Percentage of requests using Chirp 3:HD (0-100)"
+     )
+     
+     chirp3_enabled_characters: List[str] = Field(
+         default_factory=list,
+         env="CHIRP3_ENABLED_CHARACTERS",
+         description="Characters using Chirp 3:HD (comma-separated)"
+     )
+     
+     chirp3_fallback_to_wavenet: bool = Field(
+         default=True,
+         env="CHIRP3_FALLBACK_TO_WAVENET",
+         description="Fallback to WaveNet on Chirp 3:HD failure"
+     )
+ ```
+ 
+ ### Rollout Controller
+ 
+ ```python
+ class VoiceModelRouter:
+     """Routes TTS requests to appropriate voice model"""
+     
+     def __init__(self, settings: Settings):
+         self.settings = settings
+         self.random = random.Random()
+     
+     def should_use_chirp3(self, character_key: str, user_id: Optional[str] = None) -> bool:
+         """
+         Determine if request should use Chirp 3:HD
+         
+         Priority:
+         1. Global enable flag
+         2. Character-specific enable list
+         3. Percentage-based rollout
+         """
+         # Check global enable
+         if not self.settings.chirp3_enabled:
+             return False
+         
+         # Check character-specific
+         if character_key in self.settings.chirp3_enabled_characters:
+             return True
+         
+         # Percentage-based rollout (deterministic per user)
+         if user_id:
+             # Use hash for consistent per-user routing
+             hash_val = int(hashlib.md5(user_id.encode()).hexdigest()[:8], 16)
+             return (hash_val % 100) < self.settings.chirp3_rollout_percentage
+         else:
+             # Random for anonymous users
+             return self.random.randint(0, 99) < self.settings.chirp3_rollout_percentage
+     
+     def get_voice_model(self, character_key: str, user_id: Optional[str] = None) -> str:
+         """Get voice model name for request"""
+         return "chirp3-hd" if self.should_use_chirp3(character_key, user_id) else "wavenet"
+ ```
+ 
+ ### Integration in TTSService
+ 
+ ```python
+ class TTSService:
+     def __init__(self):
+         # Existing initialization...
+         self.router = VoiceModelRouter(get_settings())
+     
+     def synthesize_speech(
+         self,
+         text: str,
+         character_key: str,
+         user_id: Optional[str] = None,
+         **kwargs
+     ) -> Dict[str, Any]:
+         """
+         Synthesize speech with automatic model routing
+         """
+         # Determine voice model
+         voice_model = self.router.get_voice_model(character_key, user_id)
+         
+         try:
+             if voice_model == "chirp3-hd":
+                 return self._synthesize_chirp3(text, character_key, **kwargs)
+             else:
+                 return self._synthesize_wavenet(text, character_key, **kwargs)
+         except Exception as e:
+             # Fallback to WaveNet if Chirp 3:HD fails
+             if voice_model == "chirp3-hd" and self.router.settings.chirp3_fallback_to_wavenet:
+                 logger.warning(f"Chirp 3:HD failed, falling back to WaveNet: {e}")
+                 return self._synthesize_wavenet(text, character_key, **kwargs)
+             raise
+     
+     def _synthesize_chirp3(self, text: str, character_key: str, **kwargs) -> Dict[str, Any]:
+         """Synthesize using Chirp 3:HD"""
+         # Implementation details...
+         pass
+     
+     def _synthesize_wavenet(self, text: str, character_key: str, **kwargs) -> Dict[str, Any]:
+         """Synthesize using WaveNet (existing implementation)"""
+         # Current implementation...
+         pass
+ ```
+ 
+ ## API Changes
+ 
+ ### Backward Compatibility
+ 
+ **No breaking changes to existing endpoints:**
+ - Request schemas remain compatible (new fields optional)
+ - Response schemas unchanged
+ - Existing cached audio continues to work
+ 
+ ### Optional Feature Extensions
+ 
+ #### 1. Synthesis Request (Optional New Fields)
+ 
+ ```python
+ class SynthesizeRequest(BaseModel):
+     # Existing fields (required)
+     text: str
+     character_key: str
+     audio_type: str = "ai_response"
+     cache_enabled: bool = True
+     return_format: str = "url"
+     
+     # NEW: Optional Chirp 3:HD features
+     custom_pronunciations: Optional[List[CustomPronunciation]] = None
+     voice_controls: Optional[VoiceControlParams] = None
+     force_voice_model: Optional[str] = None  # "chirp3-hd" | "wavenet"
+ ```
+ 
+ #### 2. Synthesis Response (Extended Metadata)
+ 
+ ```python
+ class SynthesizeResponse(BaseModel):
+     # Existing fields
+     url: Optional[str] = None
+     audio_base64: Optional[str] = None
+     duration: float
+     file_size: int
+     cached: bool
+     source: str
+     character: dict
+     
+     # NEW: Voice model metadata
+     voice_model: str  # "chirp3-hd" | "wavenet"
+     voice_name: str   # Actual Google TTS voice used
+ ```
+ 
+ ## Testing Strategy
+ 
+ ### Unit Tests
+ 
+ #### 1. Voice Model Selection Tests
+ ```python
+ def test_chirp3_voice_mapping():
+     """Test all 14 characters map to valid Chirp 3:HD voices"""
+     service = TTSService()
+     for char_key in CHARACTERS:
+         voice_name = service.get_chirp3_voice_name(char_key)
+         assert voice_name.startswith("en-US-Chirp3-HD-")
+         assert service.is_valid_chirp3_voice(voice_name)
+ 
+ def test_voice_model_routing():
+     """Test feature flag routing logic"""
+     router = VoiceModelRouter(settings)
+     
+     # Global disabled
+     settings.chirp3_enabled = False
+     assert router.get_voice_model("pip_boy") == "wavenet"
+     
+     # Character-specific enabled
+     settings.chirp3_enabled = True
+     settings.chirp3_enabled_characters = ["pip_boy"]
+     assert router.get_voice_model("pip_boy") == "chirp3-hd"
+     assert router.get_voice_model("vault_dweller") == "wavenet"
+     
+     # Percentage rollout (deterministic per user)
+     settings.chirp3_rollout_percentage = 50
+     user_id = "test-user-123"
+     model1 = router.get_voice_model("pip_boy", user_id)
+     model2 = router.get_voice_model("pip_boy", user_id)
+     assert model1 == model2  # Consistent per user
+ ```
+ 
+ #### 2. Custom Pronunciation Tests
+ ```python
+ def test_custom_pronunciation_application():
+     """Test IPA pronunciation overrides"""
+     service = TTSService()
+     
+     text = "I read a book and will read it again"
+     pronunciations = [
+         CustomPronunciation(
+             phrase="read",
+             pronunciation="rÉ›d",
+             phonetic_encoding="PHONETIC_ENCODING_IPA"
+         )
+     ]
+     
+     result = service.apply_custom_pronunciations(text, pronunciations)
+     assert "rÉ›d" in result
+ 
+ def test_pronunciation_caching():
+     """Test cache keys include pronunciation parameters"""
+     text = "Test text"
+     char_key = "pip_boy"
+     
+     # Without pronunciations
+     key1 = compute_cache_key(text, char_key)
+     
+     # With pronunciations
+     pron = [CustomPronunciation(phrase="Test", pronunciation="tÉ›st")]
+     key2 = compute_cache_key(text, char_key, custom_pronunciations=pron)
+     
+     assert key1 != key2  # Different cache keys
+ ```
+ 
+ #### 3. Voice Control Tests
+ ```python
+ def test_voice_control_parameters():
+     """Test voice parameter validation and application"""
+     service = TTSService()
+     
+     controls = VoiceControlParams(
+         pitch=5.0,   # +5 semitones
+         rate=1.2,    # 1.2x speed
+         pauses=[Pause(position=10, duration="long")]
+     )
+     
+     markup = service.generate_chirp3_markup(
+         "Hello World",
+         "pip_boy",
+         voice_controls=controls
+     )
+     
+     assert "[pause long]" in markup
+     assert "pace 1.2" in markup or "1.2" in markup
+     assert "5" in markup  # Pitch value
+ 
+ def test_voice_parameter_limits():
+     """Test parameter range validation"""
+     with pytest.raises(ValueError):
+         VoiceControlParams(pitch=25.0)  # Exceeds +20 limit
+     
+     with pytest.raises(ValueError):
+         VoiceControlParams(rate=5.0)  # Exceeds 4.0 limit
+ ```
+ 
+ ### Integration Tests
+ 
+ #### 1. End-to-End Synthesis Tests
+ ```python
+ @pytest.mark.integration
+ async def test_chirp3_synthesis_pipeline():
+     """Test complete synthesis pipeline with Chirp 3:HD"""
+     request = SynthesizeRequest(
+         text="å»¢åœŸå¡”ç¾…ç³»çµ±æ­¡è¿æ‚¨",
+         character_key="pip_boy",
+         force_voice_model="chirp3-hd"
+     )
+     
+     response = await synthesize_audio(request, db, tts_service, storage_service, cache_service)
+     
+     assert response.voice_model == "chirp3-hd"
+     assert response.url is not None
+     assert response.duration > 0
+     assert response.file_size > 0
+     assert response.voice_name.startswith("en-US-Chirp3-HD-")
+ 
+ @pytest.mark.integration
+ async def test_fallback_to_wavenet():
+     """Test automatic fallback when Chirp 3:HD fails"""
+     # Mock Chirp 3:HD failure
+     with mock.patch.object(TTSService, '_synthesize_chirp3', side_effect=Exception("API Error")):
+         request = SynthesizeRequest(
+             text="Test fallback",
+             character_key="pip_boy"
+         )
+         
+         response = await synthesize_audio(request, db, tts_service, storage_service, cache_service)
+         
+         # Should fallback to WaveNet
+         assert response.voice_model == "wavenet"
+         assert response.url is not None
+ ```
+ 
+ #### 2. Performance Tests
+ ```python
+ @pytest.mark.performance
+ async def test_synthesis_performance():
+     """Test synthesis meets performance targets"""
+     import time
+     
+     text = "é€™æ˜¯ä¸€æ®µæ¨™æº–é•·åº¦çš„å¡”ç¾…è§£è®€æ–‡å­—ï¼Œå¤§ç´„äº”åå€‹å­—å·¦å³ï¼Œç”¨æ–¼æ¸¬è©¦èªéŸ³åˆæˆçš„æ€§èƒ½è¡¨ç¾ã€‚"
+     
+     start = time.time()
+     result = await tts_service.synthesize_speech(text, "pip_boy")
+     elapsed = time.time() - start
+     
+     # Target: < 2 seconds
+     assert elapsed < 2.0
+     assert result["duration"] > 0
+     assert result["file_size"] > 0
+ 
+ @pytest.mark.performance
+ async def test_cache_hit_rate():
+     """Test cache effectiveness"""
+     text = "æ¸¬è©¦å¿«å–å‘½ä¸­ç‡"
+     character_key = "pip_boy"
+     
+     # First request (cache miss)
+     response1 = await synthesize_audio(
+         SynthesizeRequest(text=text, character_key=character_key),
+         db, tts_service, storage_service, cache_service
+     )
+     assert not response1.cached
+     
+     # Second request (cache hit)
+     response2 = await synthesize_audio(
+         SynthesizeRequest(text=text, character_key=character_key),
+         db, tts_service, storage_service, cache_service
+     )
+     assert response2.cached
+     assert response2.source == "redis"
+ ```
+ 
+ ### Audio Quality Tests
+ 
+ ```python
+ @pytest.mark.audio_quality
+ def test_audio_quality_metrics():
+     """Test audio quality meets standards"""
+     # Generate sample audio
+     result = tts_service.synthesize_speech("æ¸¬è©¦éŸ³è³ª", "pip_boy")
+     audio_content = result["audio_content"]
+     
+     # Save to temporary file for analysis
+     with tempfile.NamedTemporaryFile(suffix=".mp3") as f:
+         f.write(audio_content)
+         f.flush()
+         
+         # Analyze audio properties
+         audio = AudioSegment.from_file(f.name)
+         
+         # Check sample rate (should be high quality)
+         assert audio.frame_rate >= 24000  # 24kHz+
+         
+         # Check file size (reasonable compression)
+         assert len(audio_content) < len(result["text"]) * 1000  # ~1KB per character max
+         
+         # Check duration matches estimate
+         actual_duration = len(audio) / 1000.0  # ms to seconds
+         estimated_duration = result["duration"]
+         assert abs(actual_duration - estimated_duration) < 0.5  # Within 0.5s
+ ```
+ 
+ ## Monitoring and Observability
+ 
+ ### Key Metrics
+ 
+ #### 1. Synthesis Metrics
+ ```python
+ # Prometheus metrics
+ tts_synthesis_total = Counter(
+     "tts_synthesis_total",
+     "Total TTS synthesis requests",
+     ["voice_model", "character_key", "status"]
+ )
+ 
+ tts_synthesis_duration = Histogram(
+     "tts_synthesis_duration_seconds",
+     "TTS synthesis duration",
+     ["voice_model", "character_key"]
+ )
+ 
+ tts_cache_hits = Counter(
+     "tts_cache_hits_total",
+     "Cache hit/miss counts",
+     ["voice_model", "source"]  # source: redis, db, new
+ )
+ 
+ tts_audio_file_size = Histogram(
+     "tts_audio_file_size_bytes",
+     "Audio file size distribution",
+     ["voice_model", "character_key"]
+ )
+ 
+ tts_fallback_total = Counter(
+     "tts_chirp3_fallback_total",
+     "Chirp 3:HD fallback to WaveNet count",
+     ["character_key", "error_type"]
+ )
+ ```
+ 
+ #### 2. Instrumentation Points
+ 
+ ```python
+ class TTSService:
+     def synthesize_speech(self, text: str, character_key: str, **kwargs) -> Dict[str, Any]:
+         voice_model = self.router.get_voice_model(character_key)
+         
+         start_time = time.time()
+         try:
+             if voice_model == "chirp3-hd":
+                 result = self._synthesize_chirp3(text, character_key, **kwargs)
+             else:
+                 result = self._synthesize_wavenet(text, character_key, **kwargs)
+             
+             # Record success metrics
+             duration = time.time() - start_time
+             tts_synthesis_total.labels(
+                 voice_model=voice_model,
+                 character_key=character_key,
+                 status="success"
+             ).inc()
+             tts_synthesis_duration.labels(
+                 voice_model=voice_model,
+                 character_key=character_key
+             ).observe(duration)
+             tts_audio_file_size.labels(
+                 voice_model=voice_model,
+                 character_key=character_key
+             ).observe(result["file_size"])
+             
+             return result
+             
+         except Exception as e:
+             # Record error metrics
+             tts_synthesis_total.labels(
+                 voice_model=voice_model,
+                 character_key=character_key,
+                 status="error"
+             ).inc()
+             
+             # Try fallback
+             if voice_model == "chirp3-hd" and self.router.settings.chirp3_fallback_to_wavenet:
+                 tts_fallback_total.labels(
+                     character_key=character_key,
+                     error_type=type(e).__name__
+                 ).inc()
+                 
+                 logger.warning(f"Chirp 3:HD failed, falling back: {e}")
+                 return self._synthesize_wavenet(text, character_key, **kwargs)
+             raise
+ ```
+ 
+ ### Dashboards
+ 
+ #### 1. Voice Model Comparison Dashboard
+ - Synthesis success rate by model
+ - Average synthesis time by model
+ - Audio quality metrics comparison
+ - Cache hit rates by model
+ - Error rates and fallback frequency
+ 
+ #### 2. Character Voice Dashboard
+ - Synthesis counts per character
+ - Average duration per character
+ - File size distribution per character
+ - Error rates per character
+ 
+ #### 3. Performance Dashboard
+ - P50/P95/P99 synthesis latency
+ - Cache hit rate trends
+ - API response time distribution
+ - Error rate over time
+ 
+ ## Deployment Plan
+ 
+ ### Phase 1: Infrastructure Preparation (Week 1)
+ - [ ] Update Google Cloud TTS client library
+ - [ ] Add Chirp 3:HD voice model configuration
+ - [ ] Implement feature flags and routing logic
+ - [ ] Add monitoring metrics and dashboards
+ - [ ] Set up staging environment
+ 
+ ### Phase 2: Code Implementation (Week 2-3)
+ - [ ] Implement Chirp 3:HD voice mapping
+ - [ ] Add custom pronunciation support
+ - [ ] Implement enhanced voice controls
+ - [ ] Update cache key computation
+ - [ ] Add comprehensive unit tests
+ 
+ ### Phase 3: Integration Testing (Week 4)
+ - [ ] End-to-end integration tests
+ - [ ] Performance benchmarking
+ - [ ] Audio quality assessment
+ - [ ] Backward compatibility verification
+ - [ ] Load testing
+ 
+ ### Phase 4: Gradual Rollout (Week 5-6)
+ - [ ] **Day 1-2:** Enable for 1 test character (pip_boy) at 10%
+ - [ ] **Day 3-4:** Increase to 50% for test character
+ - [ ] **Day 5-7:** Enable for 3 characters at 25%
+ - [ ] **Week 2:** Enable for all characters at 50%
+ - [ ] **Week 3:** Increase to 100% with monitoring
+ 
+ ### Phase 5: WaveNet Deprecation (Week 7+)
+ - [ ] Confirm Chirp 3:HD stability (95%+ success rate)
+ - [ ] Disable WaveNet fallback for non-critical paths
+ - [ ] Remove WaveNet-specific code (keep for emergency rollback)
+ - [ ] Archive WaveNet configuration
+ 
+ ### Rollback Triggers
+ - Synthesis error rate > 5%
+ - Cache hit rate drop > 20%
+ - User complaints about audio quality
+ - Performance degradation > 50%
+ 
+ ## Risk Mitigation
+ 
+ ### Technical Risks
+ 
+ | Risk                                | Impact | Likelihood | Mitigation Strategy                                |
+ | ----------------------------------- | ------ | ---------- | -------------------------------------------------- |
+ | Chirp 3:HD API instability          | High   | Medium     | Feature flags, automatic fallback to WaveNet       |
+ | Voice quality regression            | High   | Low        | A/B testing, user feedback collection              |
+ | Performance degradation             | Medium | Low        | Performance tests, caching optimization            |
+ | Chinese voice quality issues        | High   | Medium     | Test extensively, consider hybrid approach         |
+ | Quota exhaustion                    | Medium | Low        | Monitor usage, set up quota alerts                 |
+ | Cache invalidation issues           | Medium | Medium     | Dual caching strategy, versioned cache keys        |
+ | Breaking API changes                | High   | Low        | Strict backward compatibility, comprehensive tests |
+ 
+ ### Operational Risks
+ 
+ | Risk                        | Impact | Likelihood | Mitigation Strategy                           |
+ | --------------------------- | ------ | ---------- | --------------------------------------------- |
+ | Deployment failures         | High   | Low        | Staged rollout, automated rollback            |
+ | Monitoring blind spots      | Medium | Medium     | Comprehensive metrics, alerting               |
+ | Cost overruns               | Medium | Low        | Usage monitoring, budget alerts               |
+ | Insufficient testing        | High   | Medium     | Comprehensive test suite, staging environment |
+ 
+ ## Open Questions
+ 
+ 1. **Chinese Voice Availability:** Are native Chinese Chirp 3:HD voices available? If not, what is the timeline?
+ 2. **Cross-lingual Quality:** How does Chirp 3:HD handle Chinese text with English voices? Audio quality acceptable?
+ 3. **Quota Limits:** What are Google Cloud TTS quotas for Chirp 3:HD? Different from WaveNet?
+ 4. **Pricing:** Cost difference between Chirp 3:HD and WaveNet?
+ 5. **Voice Consistency:** Can we ensure voice characteristics remain consistent across Chirp 3:HD updates?
+ 
+ ## Success Metrics
+ 
+ ### Quantitative Metrics
+ - **Audio Quality:** > 4.0/5.0 user rating (if collected)
+ - **Synthesis Performance:** < 2 seconds for 90% of requests
+ - **Cache Hit Rate:** > 90% (maintained or improved)
+ - **Error Rate:** < 1% synthesis failures
+ - **Fallback Rate:** < 5% fallback to WaveNet
+ 
+ ### Qualitative Metrics
+ - User feedback on voice quality
+ - Stakeholder approval of character voice mapping
+ - Developer satisfaction with API design
+ - Documentation completeness
+ 
+ ## Conclusion
+ 
+ This design provides a comprehensive plan for upgrading to Chirp 3:HD while maintaining backward compatibility and system stability. The phased rollout approach with feature flags ensures we can safely test and validate the new system before full deployment. The dual-model support and automatic fallback mechanisms minimize risk, while the enhanced monitoring provides visibility into system performance and quality.
+ 
+ **Next Steps:**
+ 1. Review and approve this design document
+ 2. Generate implementation tasks breakdown
+ 3. Begin Phase 1 infrastructure preparation
+ 4. Set up staging environment for testing
```

</details>

---

Tool use: **search_replace**


<details><summary>Edit file: .kiro/specs/chirp3-hd-tts-system/spec.json</summary>

**Chunk 1**
Lines added: 4, lines removed: 4

```diff
@@ -2,14 +2,14 @@
    "feature_name": "chirp3-hd-tts-system",
    "created_at": "2025-11-03T16:19:08Z",
-   "updated_at": "2025-11-03T16:20:08Z",
+   "updated_at": "2025-11-03T16:21:25Z",
    "language": "en",
-   "phase": "requirements_generated",
+   "phase": "design_generated",
    "approvals": {
      "requirements": {
        "generated": true,
-       "approved": false
+       "approved": true
      },
      "design": {
-       "generated": false,
+       "generated": true,
        "approved": false
      },
```

</details>

---

Tool use: **todo_write**

## Todo List

- [x] Generate comprehensive requirements for Chirp 3:HD TTS system implementation
- [x] Generate technical design for Chirp 3:HD TTS system with voice mapping, pronunciation support, and rollout strategy

---

ğŸ¤–

## æŠ€è¡“è¨­è¨ˆå·²å®Œæˆ

å·²æ ¹æ“šéœ€æ±‚æ–‡ä»¶ç”¢ç”Ÿå®Œæ•´çš„æŠ€è¡“è¨­è¨ˆæ–‡ä»¶ï¼Œæ¶µè“‹ä»¥ä¸‹æ ¸å¿ƒæ¶æ§‹ï¼š

### è¨­è¨ˆé‡é»

**1. èªéŸ³æ¨¡å‹æ˜ å°„ç­–ç•¥**
- 14 å€‹ Fallout è§’è‰²å®Œæ•´æ˜ å°„åˆ° Chirp 3:HD èªéŸ³
- æ ¹æ“šæ€§åˆ¥ã€å€‹æ€§ã€éŸ³èª¿ç‰¹å¾µç²¾å¿ƒé¸æ“‡èªéŸ³
- ä¿ç•™ç¾æœ‰ pitch/rate åƒæ•¸ä»¥ç¶­æŒè§’è‰²å€‹æ€§

**2. è‡ªè¨‚ç™¼éŸ³æ”¯æ´**
- IPA éŸ³æ¨™ç·¨ç¢¼ç³»çµ±
- å…¨åŸŸç™¼éŸ³å­—å…¸ + å–®æ¬¡è¦†å¯«æ©Ÿåˆ¶
- èˆ‡ç¾æœ‰ SSML ç”Ÿæˆç³»çµ±æ•´åˆ

**3. å¢å¼·èªéŸ³æ§åˆ¶**
- èªé€Ÿæ§åˆ¶ï¼ˆ0.25x - 4.0xï¼‰
- éŸ³é«˜èª¿æ•´ï¼ˆ-20 to +20 åŠéŸ³ï¼‰
- è‡ªè¨‚åœé “åŠŸèƒ½
- åƒæ•¸ç¹¼æ‰¿èˆ‡é‹è¡Œæ™‚è¦†å¯«

**4. å¿«å–ç­–ç•¥å‡ç´š**
- ç‰ˆæœ¬åŒ– cache keyï¼ˆåŒ…å«æ¨¡å‹ç‰ˆæœ¬ï¼‰
- é›™å¿«å–å‘½åç©ºé–“ï¼ˆæ”¯æ´å¹³æ»‘é·ç§»ï¼‰
- åƒæ•¸ hash åŒ…å«ç™¼éŸ³å’ŒèªéŸ³æ§åˆ¶

**5. åŠŸèƒ½æ——æ¨™èˆ‡æ¼¸é€²å¼ç™¼å¸ƒ**
- å…¨åŸŸ/è§’è‰²ç´šåˆ¥å•Ÿç”¨é–‹é—œ
- ç™¾åˆ†æ¯”å¼æµé‡æ§åˆ¶
- è‡ªå‹•é™ç´šè‡³ WaveNet
- æ¯ç”¨æˆ¶ä¸€è‡´æ€§è·¯ç”±

**6. å‘å¾Œç›¸å®¹æ€§ä¿è­‰**
- é›¶ API ç ´å£æ€§è®Šæ›´
- ç¾æœ‰å¿«å–ç¹¼çºŒæœ‰æ•ˆ
- å¯é¸çš„æ–°åŠŸèƒ½æ¬„ä½
- è‡ªå‹• fallback æ©Ÿåˆ¶

### éƒ¨ç½²è¨ˆç•«

**Phase 1-2 (Week 1-3):** åŸºç¤è¨­æ–½æº–å‚™èˆ‡ç¨‹å¼ç¢¼å¯¦ä½œ  
**Phase 3-4 (Week 4-6):** æ•´åˆæ¸¬è©¦èˆ‡æ¼¸é€²å¼ç™¼å¸ƒï¼ˆ10% â†’ 50% â†’ 100%ï¼‰  
**Phase 5 (Week 7+):** WaveNet æ£„ç”¨ï¼ˆä¿ç•™ç·Šæ€¥å›æ»¾èƒ½åŠ›ï¼‰

### é¢¨éšªæ§ç®¡

- æŠ€è¡“é¢¨éšªï¼šAPI ä¸ç©©å®šã€èªéŸ³å“è³ªå›æ­¸ã€æ•ˆèƒ½ä¸‹é™
- ç·©è§£æªæ–½ï¼šåŠŸèƒ½æ——æ¨™ã€è‡ªå‹•é™ç´šã€A/B æ¸¬è©¦ã€å…¨é¢ç›£æ§

### ç›£æ§æŒ‡æ¨™

- åˆæˆæˆåŠŸç‡ã€å»¶é²ã€å¿«å–å‘½ä¸­ç‡
- éŸ³æª”å¤§å°åˆ†å¸ƒã€éŒ¯èª¤ç‡
- Chirp 3:HD vs WaveNet æ•ˆèƒ½å°æ¯”

## ä¸‹ä¸€æ­¥
```bash
/kiro:spec-tasks chirp3-hd-tts-system
```

## å‚™è¨»
è¨­è¨ˆæ–‡ä»¶å·²æº–å‚™å¥½ä¾›ä»»å‹™åˆ†è§£éšæ®µä½¿ç”¨ã€‚å»ºè­°å…ˆç¢ºèªé–‹æ”¾å•é¡Œï¼ˆä¸­æ–‡èªéŸ³å¯ç”¨æ€§ã€è·¨èªè¨€å“è³ªã€é…é¡é™åˆ¶ã€å®šåƒ¹å·®ç•°ï¼‰å†é€²å…¥å¯¦ä½œéšæ®µã€‚

---

_**User (2025-11-03 16:17Z)**_

/kiro:spec-tasks chirp3-hd-tts-system

---

_**Assistant (claude-4.5-sonnet)**_

Tool use: **read_file**

Read file: .kiro/specs/chirp3-hd-tts-system/spec.json

---

Tool use: **read_file**

Read file: .kiro/specs/chirp3-hd-tts-system/design.md

---

Tool use: **run_terminal_cmd**

```bash
date -u +"%Y-%m-%dT%H:%M:%SZ"
```

```
2025-11-03T16:26:36Z

```

---

Tool use: **write**


<details><summary>Edit file: .kiro/specs/chirp3-hd-tts-system/tasks.md</summary>

**Chunk 1**
Lines added: 1271, lines removed: 1

```diff
@@ -1,1 +1,1271 @@
- 
+ # Implementation Tasks
+ 
+ ## Task Overview
+ 
+ This document breaks down the Chirp 3:HD TTS system upgrade into actionable implementation tasks, organized by phase and priority. Each task includes acceptance criteria, estimated complexity, and dependencies.
+ 
+ ---
+ 
+ ## Phase 1: Infrastructure and Configuration (Week 1)
+ 
+ ### Task 1.1: Update Google Cloud TTS Dependencies
+ **Priority:** Critical  
+ **Estimated Effort:** 2 hours  
+ **Dependencies:** None
+ 
+ **Description:**
+ Update Google Cloud TTS client library to support Chirp 3:HD features.
+ 
+ **Implementation Steps:**
+ 1. Update `google-cloud-texttospeech` package in `backend/pyproject.toml`
+ 2. Verify API compatibility with existing code
+ 3. Test credential loading mechanisms
+ 4. Update import statements if needed
+ 
+ **Files to Modify:**
+ - `backend/pyproject.toml`
+ - `backend/uv.lock` (regenerate)
+ 
+ **Acceptance Criteria:**
+ - [ ] Package updated to latest stable version
+ - [ ] All existing TTS tests pass
+ - [ ] No breaking changes to credential loading
+ - [ ] Documentation updated with version requirements
+ 
+ **Testing:**
+ ```bash
+ cd backend
+ uv sync
+ uv run pytest tests/unit/test_tts_service.py -v
+ ```
+ 
+ ---
+ 
+ ### Task 1.2: Add Chirp 3:HD Voice Configuration
+ **Priority:** Critical  
+ **Estimated Effort:** 4 hours  
+ **Dependencies:** Task 1.1
+ 
+ **Description:**
+ Create configuration for Chirp 3:HD voice mapping and character assignments.
+ 
+ **Implementation Steps:**
+ 1. Create `CHIRP3_VOICE_MAPPING` constant in `tts_service.py`
+ 2. Document voice selection rationale for each character
+ 3. Create voice configuration validation function
+ 4. Add voice model enum (`VoiceModel.CHIRP3_HD`, `VoiceModel.WAVENET`)
+ 
+ **Files to Modify:**
+ - `backend/app/services/tts_service.py`
+ 
+ **New Code:**
+ ```python
+ from enum import Enum
+ 
+ class VoiceModel(str, Enum):
+     WAVENET = "wavenet"
+     CHIRP3_HD = "chirp3-hd"
+ 
+ # Chirp 3:HD voice mapping for all 14 characters
+ CHIRP3_VOICE_MAPPING = {
+     "super_mutant": "en-US-Chirp3-HD-Algenib",
+     "brotherhood_paladin": "en-US-Chirp3-HD-Algieba",
+     "legion_centurion": "en-US-Chirp3-HD-Alnilam",
+     "ghoul": "en-US-Chirp3-HD-Mizar",
+     "wasteland_trader": "en-US-Chirp3-HD-Vega",
+     "ncr_ranger": "en-US-Chirp3-HD-Deneb",
+     "pip_boy": "en-US-Chirp3-HD-Regulus",
+     "minuteman": "en-US-Chirp3-HD-Altair",
+     "vault_dweller": "en-US-Chirp3-HD-Aoede",
+     "railroad_agent": "en-US-Chirp3-HD-Leda",
+     "brotherhood_scribe": "en-US-Chirp3-HD-Callisto",
+     "codsworth": "en-US-Chirp3-HD-Fomalhaut",
+     "raider": "en-US-Chirp3-HD-Hadar",
+     "institute_scientist": "en-US-Chirp3-HD-Kore",
+ }
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] All 14 characters have Chirp 3:HD voice assignments
+ - [ ] Voice mapping validated against Google TTS API
+ - [ ] Voice selection rationale documented
+ - [ ] Voice model enum created
+ 
+ ---
+ 
+ ### Task 1.3: Add Feature Flags for Chirp 3:HD
+ **Priority:** Critical  
+ **Estimated Effort:** 3 hours  
+ **Dependencies:** None
+ 
+ **Description:**
+ Implement feature flags to control Chirp 3:HD rollout at global, character, and user levels.
+ 
+ **Implementation Steps:**
+ 1. Add Chirp 3:HD settings to `backend/app/config.py`
+ 2. Create `VoiceModelRouter` class for routing logic
+ 3. Implement percentage-based rollout with user-consistent hashing
+ 4. Add environment variable documentation
+ 
+ **Files to Modify:**
+ - `backend/app/config.py`
+ - `backend/app/services/tts_service.py` (new class)
+ - `backend/.env.example`
+ 
+ **New Settings:**
+ ```python
+ class Settings(BaseSettings):
+     # ... existing settings ...
+     
+     # Chirp 3:HD Feature Flags
+     chirp3_enabled: bool = Field(
+         default=False,
+         env="CHIRP3_ENABLED"
+     )
+     chirp3_rollout_percentage: int = Field(
+         default=0,
+         ge=0,
+         le=100,
+         env="CHIRP3_ROLLOUT_PERCENTAGE"
+     )
+     chirp3_enabled_characters: str = Field(
+         default="",
+         env="CHIRP3_ENABLED_CHARACTERS"
+     )
+     chirp3_fallback_to_wavenet: bool = Field(
+         default=True,
+         env="CHIRP3_FALLBACK_TO_WAVENET"
+     )
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] Feature flags added to settings
+ - [ ] `VoiceModelRouter` class implemented
+ - [ ] Percentage-based routing works correctly
+ - [ ] User-consistent routing verified
+ - [ ] Environment variables documented
+ 
+ **Testing:**
+ ```python
+ def test_voice_model_routing():
+     router = VoiceModelRouter(settings)
+     
+     # Global disabled
+     settings.chirp3_enabled = False
+     assert router.get_voice_model("pip_boy") == VoiceModel.WAVENET
+     
+     # Character-specific enabled
+     settings.chirp3_enabled = True
+     settings.chirp3_enabled_characters = "pip_boy,vault_dweller"
+     assert router.get_voice_model("pip_boy") == VoiceModel.CHIRP3_HD
+     
+     # Percentage rollout
+     settings.chirp3_rollout_percentage = 50
+     user_id = "test-user-123"
+     model = router.get_voice_model("pip_boy", user_id)
+     assert model in [VoiceModel.CHIRP3_HD, VoiceModel.WAVENET]
+ ```
+ 
+ ---
+ 
+ ### Task 1.4: Add Monitoring Metrics
+ **Priority:** High  
+ **Estimated Effort:** 3 hours  
+ **Dependencies:** Task 1.2
+ 
+ **Description:**
+ Add Prometheus metrics for tracking Chirp 3:HD synthesis performance and quality.
+ 
+ **Implementation Steps:**
+ 1. Define metrics in `backend/app/core/metrics.py` (create if not exists)
+ 2. Add instrumentation to `TTSService.synthesize_speech()`
+ 3. Create Grafana dashboard JSON (optional)
+ 4. Document metrics in README
+ 
+ **Files to Create/Modify:**
+ - `backend/app/core/metrics.py` (new)
+ - `backend/app/services/tts_service.py`
+ 
+ **New Metrics:**
+ ```python
+ from prometheus_client import Counter, Histogram
+ 
+ tts_synthesis_total = Counter(
+     "tts_synthesis_total",
+     "Total TTS synthesis requests",
+     ["voice_model", "character_key", "status"]
+ )
+ 
+ tts_synthesis_duration = Histogram(
+     "tts_synthesis_duration_seconds",
+     "TTS synthesis duration",
+     ["voice_model", "character_key"],
+     buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0]
+ )
+ 
+ tts_cache_hits = Counter(
+     "tts_cache_hits_total",
+     "Cache hit/miss counts",
+     ["voice_model", "source"]
+ )
+ 
+ tts_audio_file_size = Histogram(
+     "tts_audio_file_size_bytes",
+     "Audio file size distribution",
+     ["voice_model", "character_key"],
+     buckets=[1000, 5000, 10000, 50000, 100000]
+ )
+ 
+ tts_fallback_total = Counter(
+     "tts_chirp3_fallback_total",
+     "Chirp 3:HD fallback to WaveNet count",
+     ["character_key", "error_type"]
+ )
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] All metrics defined
+ - [ ] Instrumentation added to synthesis methods
+ - [ ] Metrics exported at `/metrics` endpoint
+ - [ ] Documentation updated
+ 
+ ---
+ 
+ ## Phase 2: Core Implementation (Week 2-3)
+ 
+ ### Task 2.1: Implement Chirp 3:HD Synthesis Method
+ **Priority:** Critical  
+ **Estimated Effort:** 6 hours  
+ **Dependencies:** Task 1.1, 1.2, 1.3
+ 
+ **Description:**
+ Implement the core `_synthesize_chirp3()` method for Chirp 3:HD voice synthesis.
+ 
+ **Implementation Steps:**
+ 1. Create `_synthesize_chirp3()` method in `TTSService`
+ 2. Generate Chirp 3:HD-specific markup (not SSML)
+ 3. Set proper audio configuration for HD quality
+ 4. Handle Chirp 3:HD-specific errors
+ 5. Add logging for debugging
+ 
+ **Files to Modify:**
+ - `backend/app/services/tts_service.py`
+ 
+ **New Method:**
+ ```python
+ def _synthesize_chirp3(
+     self,
+     text: str,
+     character_key: str,
+     custom_pronunciations: Optional[List[CustomPronunciation]] = None,
+     voice_controls: Optional[VoiceControlParams] = None
+ ) -> Dict[str, Any]:
+     """
+     Synthesize speech using Chirp 3:HD model
+     
+     Args:
+         text: Text to synthesize
+         character_key: Character identifier
+         custom_pronunciations: Optional pronunciation overrides
+         voice_controls: Optional voice control parameters
+     
+     Returns:
+         Synthesis result with audio content and metadata
+     """
+     # Get Chirp 3:HD voice name
+     voice_name = CHIRP3_VOICE_MAPPING.get(character_key)
+     if not voice_name:
+         raise ValueError(f"No Chirp 3:HD voice for character: {character_key}")
+     
+     # Get voice parameters
+     pitch, rate = self.convert_voice_params(character_key)
+     
+     # Apply overrides if present
+     if voice_controls:
+         pitch = voice_controls.pitch if voice_controls.pitch is not None else pitch
+         rate = voice_controls.rate if voice_controls.rate is not None else rate
+     
+     # Generate Chirp 3:HD markup
+     markup_text = self.generate_chirp3_markup(
+         text,
+         character_key,
+         custom_pronunciations,
+         voice_controls
+     )
+     
+     # Create synthesis input
+     synthesis_input = texttospeech.SynthesisInput(
+         markup=markup_text,
+         custom_pronunciations=self._build_custom_pronunciations(custom_pronunciations)
+     )
+     
+     # Create voice params
+     voice = texttospeech.VoiceSelectionParams(
+         language_code="en-US",
+         name=voice_name
+     )
+     
+     # Create audio config (HD quality)
+     audio_config = texttospeech.AudioConfig(
+         audio_encoding=texttospeech.AudioEncoding.MP3,
+         speaking_rate=1.0,  # Controlled via markup
+         pitch=0.0,          # Controlled via markup
+         sample_rate_hertz=24000,  # HD quality
+     )
+     
+     # Synthesize
+     response = self.client.synthesize_speech(
+         input=synthesis_input,
+         voice=voice,
+         audio_config=audio_config
+     )
+     
+     # Process response
+     audio_content = response.audio_content
+     estimated_duration = (len(text) * 0.15) / rate
+     
+     return {
+         "audio_content": audio_content,
+         "duration": estimated_duration,
+         "file_size": len(audio_content),
+         "text_length": len(text),
+         "voice_name": voice_name,
+         "voice_model": "chirp3-hd",
+         "ssml_params": {"pitch": pitch, "rate": rate}
+     }
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] Method successfully synthesizes speech with Chirp 3:HD
+ - [ ] Voice parameters applied correctly
+ - [ ] HD audio quality (24kHz sample rate)
+ - [ ] Error handling implemented
+ - [ ] Logging added
+ 
+ **Testing:**
+ ```python
+ @pytest.mark.integration
+ def test_chirp3_synthesis():
+     service = TTSService()
+     result = service._synthesize_chirp3(
+         "æ¸¬è©¦ Chirp 3:HD èªéŸ³åˆæˆ",
+         "pip_boy"
+     )
+     
+     assert result["voice_model"] == "chirp3-hd"
+     assert result["voice_name"].startswith("en-US-Chirp3-HD-")
+     assert result["audio_content"] is not None
+     assert result["file_size"] > 0
+ ```
+ 
+ ---
+ 
+ ### Task 2.2: Implement Voice Model Routing in synthesize_speech()
+ **Priority:** Critical  
+ **Estimated Effort:** 4 hours  
+ **Dependencies:** Task 1.3, 2.1
+ 
+ **Description:**
+ Integrate voice model routing and fallback logic into the main `synthesize_speech()` method.
+ 
+ **Implementation Steps:**
+ 1. Modify `synthesize_speech()` to use `VoiceModelRouter`
+ 2. Add automatic fallback to WaveNet on Chirp 3:HD failure
+ 3. Add metrics instrumentation
+ 4. Update return type to include voice model info
+ 
+ **Files to Modify:**
+ - `backend/app/services/tts_service.py`
+ 
+ **Modified Method:**
+ ```python
+ def synthesize_speech(
+     self,
+     text: str,
+     character_key: str,
+     language_code: str = "zh-TW",
+     return_base64: bool = False,
+     user_id: Optional[str] = None,
+     custom_pronunciations: Optional[List[CustomPronunciation]] = None,
+     voice_controls: Optional[VoiceControlParams] = None
+ ) -> Dict[str, Any]:
+     """Synthesize speech with automatic model routing"""
+     
+     # Determine voice model
+     voice_model = self.router.get_voice_model(character_key, user_id)
+     
+     start_time = time.time()
+     try:
+         # Route to appropriate synthesis method
+         if voice_model == VoiceModel.CHIRP3_HD:
+             result = self._synthesize_chirp3(
+                 text, character_key, custom_pronunciations, voice_controls
+             )
+         else:
+             result = self._synthesize_wavenet(text, character_key)
+         
+         # Record metrics
+         duration = time.time() - start_time
+         tts_synthesis_total.labels(
+             voice_model=voice_model.value,
+             character_key=character_key,
+             status="success"
+         ).inc()
+         tts_synthesis_duration.labels(
+             voice_model=voice_model.value,
+             character_key=character_key
+         ).observe(duration)
+         
+         # Add base64 if requested
+         if return_base64:
+             audio_base64 = base64.b64encode(result["audio_content"]).decode()
+             result["audio_base64"] = f"data:audio/mp3;base64,{audio_base64}"
+         
+         return result
+         
+     except Exception as e:
+         # Record error
+         tts_synthesis_total.labels(
+             voice_model=voice_model.value,
+             character_key=character_key,
+             status="error"
+         ).inc()
+         
+         # Try fallback
+         if voice_model == VoiceModel.CHIRP3_HD and self.router.settings.chirp3_fallback_to_wavenet:
+             logger.warning(f"Chirp 3:HD failed, falling back to WaveNet: {e}")
+             tts_fallback_total.labels(
+                 character_key=character_key,
+                 error_type=type(e).__name__
+             ).inc()
+             
+             return self._synthesize_wavenet(text, character_key)
+         
+         raise
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] Voice model routing works correctly
+ - [ ] Automatic fallback to WaveNet on Chirp 3:HD failure
+ - [ ] Metrics recorded for all paths
+ - [ ] Backward compatibility maintained
+ 
+ ---
+ 
+ ### Task 2.3: Refactor WaveNet Code into _synthesize_wavenet()
+ **Priority:** Medium  
+ **Estimated Effort:** 2 hours  
+ **Dependencies:** Task 2.2
+ 
+ **Description:**
+ Extract current WaveNet synthesis code into dedicated `_synthesize_wavenet()` method for clean separation.
+ 
+ **Implementation Steps:**
+ 1. Create `_synthesize_wavenet()` method
+ 2. Move existing SSML-based synthesis code
+ 3. Ensure return format matches `_synthesize_chirp3()`
+ 4. Add voice_model field to return value
+ 
+ **Files to Modify:**
+ - `backend/app/services/tts_service.py`
+ 
+ **Acceptance Criteria:**
+ - [ ] WaveNet code extracted to separate method
+ - [ ] Return format consistent with Chirp 3:HD
+ - [ ] All existing tests pass
+ - [ ] No behavior changes for WaveNet path
+ 
+ ---
+ 
+ ### Task 2.4: Implement Custom Pronunciation Support
+ **Priority:** High  
+ **Estimated Effort:** 5 hours  
+ **Dependencies:** Task 2.1
+ 
+ **Description:**
+ Implement custom pronunciation override system using IPA phonetic encoding.
+ 
+ **Implementation Steps:**
+ 1. Create `CustomPronunciation` Pydantic model
+ 2. Create `PronunciationDictionary` class for global entries
+ 3. Implement `apply_custom_pronunciations()` method
+ 4. Integrate with Chirp 3:HD markup generation
+ 5. Update cache key computation to include pronunciations
+ 
+ **Files to Modify:**
+ - `backend/app/schemas/audio.py` (new models)
+ - `backend/app/services/tts_service.py`
+ 
+ **New Models:**
+ ```python
+ # In backend/app/schemas/audio.py
+ from pydantic import BaseModel, Field
+ 
+ class CustomPronunciation(BaseModel):
+     phrase: str = Field(..., description="Text to override")
+     pronunciation: str = Field(..., description="IPA phonetic spelling")
+     phonetic_encoding: str = Field(
+         default="PHONETIC_ENCODING_IPA",
+         description="Phonetic encoding type"
+     )
+ 
+ class PronunciationDictionary:
+     """Global pronunciation dictionary for common terms"""
+     
+     def __init__(self):
+         self.entries: Dict[str, str] = {
+             "Pip-Boy": "pÉªp bÉ”Éª",
+             "Tarot": "ËˆtÃ¦.roÊŠ",
+             # Add more common terms
+         }
+     
+     def add_entry(self, phrase: str, ipa: str) -> None:
+         self.entries[phrase] = ipa
+     
+     def get_pronunciation(self, phrase: str) -> Optional[str]:
+         return self.entries.get(phrase)
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] CustomPronunciation model created
+ - [ ] Pronunciation dictionary implemented
+ - [ ] Pronunciations applied to Chirp 3:HD synthesis
+ - [ ] Cache keys include pronunciation parameters
+ - [ ] Unit tests pass
+ 
+ **Testing:**
+ ```python
+ def test_custom_pronunciation():
+     service = TTSService()
+     pronunciations = [
+         CustomPronunciation(
+             phrase="read",
+             pronunciation="rÉ›d"
+         )
+     ]
+     
+     result = service._synthesize_chirp3(
+         "I read a book",
+         "pip_boy",
+         custom_pronunciations=pronunciations
+     )
+     
+     assert result["audio_content"] is not None
+ ```
+ 
+ ---
+ 
+ ### Task 2.5: Implement Enhanced Voice Controls
+ **Priority:** Medium  
+ **Estimated Effort:** 4 hours  
+ **Dependencies:** Task 2.1
+ 
+ **Description:**
+ Implement advanced voice control features including custom pauses and runtime parameter overrides.
+ 
+ **Implementation Steps:**
+ 1. Create `VoiceControlParams` and `Pause` Pydantic models
+ 2. Implement `_insert_pauses()` method
+ 3. Implement `generate_chirp3_markup()` with pause support
+ 4. Add parameter validation (range checks)
+ 
+ **Files to Modify:**
+ - `backend/app/schemas/audio.py`
+ - `backend/app/services/tts_service.py`
+ 
+ **New Models:**
+ ```python
+ class Pause(BaseModel):
+     position: int = Field(..., ge=0, description="Character position")
+     duration: str = Field(..., pattern="^(short|medium|long|\\d+ms)$")
+ 
+ class VoiceControlParams(BaseModel):
+     pitch: Optional[float] = Field(None, ge=-20.0, le=20.0)
+     rate: Optional[float] = Field(None, ge=0.25, le=4.0)
+     volume: Optional[float] = Field(None, ge=0.0, le=1.0)
+     pauses: Optional[List[Pause]] = None
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] Voice control models created with validation
+ - [ ] Pause insertion working correctly
+ - [ ] Parameter overrides applied
+ - [ ] Range validation prevents invalid values
+ 
+ ---
+ 
+ ### Task 2.6: Update Cache Key Computation
+ **Priority:** High  
+ **Estimated Effort:** 3 hours  
+ **Dependencies:** Task 2.4, 2.5
+ 
+ **Description:**
+ Update cache key generation to include voice model version, pronunciations, and voice controls.
+ 
+ **Implementation Steps:**
+ 1. Create new `compute_cache_key()` function
+ 2. Include all synthesis parameters in hash
+ 3. Update `synthesize_audio` endpoint to use new function
+ 4. Add cache key unit tests
+ 
+ **Files to Modify:**
+ - `backend/app/services/tts_service.py`
+ - `backend/app/api/v1/endpoints/audio.py`
+ 
+ **New Function:**
+ ```python
+ def compute_cache_key(
+     text: str,
+     character_key: str,
+     voice_model: VoiceModel,
+     custom_pronunciations: Optional[List[CustomPronunciation]] = None,
+     voice_controls: Optional[VoiceControlParams] = None
+ ) -> str:
+     """Compute comprehensive cache key"""
+     components = [text, character_key, voice_model.value]
+     
+     if custom_pronunciations:
+         pron_str = "|".join(
+             f"{p.phrase}:{p.pronunciation}"
+             for p in sorted(custom_pronunciations, key=lambda x: x.phrase)
+         )
+         components.append(pron_str)
+     
+     if voice_controls:
+         ctrl_parts = []
+         if voice_controls.pitch is not None:
+             ctrl_parts.append(f"p{voice_controls.pitch}")
+         if voice_controls.rate is not None:
+             ctrl_parts.append(f"r{voice_controls.rate}")
+         if ctrl_parts:
+             components.append("_".join(ctrl_parts))
+     
+     return hashlib.sha256(":".join(components).encode()).hexdigest()
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] Cache keys include all synthesis parameters
+ - [ ] Different parameters produce different keys
+ - [ ] Same parameters produce consistent keys
+ - [ ] Unit tests verify hashing logic
+ 
+ ---
+ 
+ ### Task 2.7: Update API Request/Response Schemas
+ **Priority:** Medium  
+ **Estimated Effort:** 2 hours  
+ **Dependencies:** Task 2.4, 2.5
+ 
+ **Description:**
+ Extend API schemas to support new Chirp 3:HD features while maintaining backward compatibility.
+ 
+ **Implementation Steps:**
+ 1. Add optional fields to `SynthesizeRequest`
+ 2. Add voice model metadata to `SynthesizeResponse`
+ 3. Update OpenAPI documentation
+ 4. Ensure all fields optional (no breaking changes)
+ 
+ **Files to Modify:**
+ - `backend/app/api/v1/endpoints/audio.py`
+ 
+ **Updated Schemas:**
+ ```python
+ class SynthesizeRequest(BaseModel):
+     # Existing required fields
+     text: str = Field(..., min_length=1, max_length=5000)
+     character_key: str = Field(..., pattern="^[a-z_]+$")
+     audio_type: str = Field(default="ai_response")
+     cache_enabled: bool = Field(default=True)
+     return_format: str = Field(default="url")
+     
+     # NEW: Optional Chirp 3:HD features
+     custom_pronunciations: Optional[List[CustomPronunciation]] = None
+     voice_controls: Optional[VoiceControlParams] = None
+     force_voice_model: Optional[str] = Field(
+         None,
+         pattern="^(chirp3-hd|wavenet)$"
+     )
+ 
+ class SynthesizeResponse(BaseModel):
+     # Existing fields
+     url: Optional[str] = None
+     audio_base64: Optional[str] = None
+     duration: float
+     file_size: int
+     cached: bool
+     source: str
+     character: dict
+     
+     # NEW: Voice model metadata
+     voice_model: str
+     voice_name: str
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] New fields added as optional
+ - [ ] Existing API calls work unchanged
+ - [ ] OpenAPI docs updated
+ - [ ] Schema validation working
+ 
+ ---
+ 
+ ## Phase 3: Testing (Week 4)
+ 
+ ### Task 3.1: Write Unit Tests for Chirp 3:HD Components
+ **Priority:** Critical  
+ **Estimated Effort:** 6 hours  
+ **Dependencies:** Phase 2 complete
+ 
+ **Description:**
+ Comprehensive unit tests for all new Chirp 3:HD functionality.
+ 
+ **Implementation Steps:**
+ 1. Test voice model routing logic
+ 2. Test custom pronunciation application
+ 3. Test voice control parameters
+ 4. Test cache key computation
+ 5. Test fallback mechanisms
+ 
+ **Files to Create:**
+ - `backend/tests/unit/test_chirp3_synthesis.py`
+ - `backend/tests/unit/test_voice_model_routing.py`
+ - `backend/tests/unit/test_custom_pronunciation.py`
+ 
+ **Test Coverage:**
+ ```python
+ # Test voice mapping
+ def test_all_characters_have_chirp3_voices():
+     for char_key in DEFAULT_VOICE_CONFIGS.keys():
+         assert char_key in CHIRP3_VOICE_MAPPING
+ 
+ # Test routing
+ def test_voice_model_routing_with_feature_flags():
+     # Global enabled/disabled
+     # Character-specific
+     # Percentage rollout
+     # User consistency
+ 
+ # Test pronunciations
+ def test_custom_pronunciation_cache_keys():
+     # Same text, different pronunciations = different keys
+     
+ # Test voice controls
+ def test_voice_control_validation():
+     # Valid ranges pass
+     # Invalid ranges raise errors
+ 
+ # Test fallback
+ def test_chirp3_fallback_to_wavenet():
+     # Mock Chirp 3:HD failure
+     # Verify WaveNet called
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] Test coverage > 90% for new code
+ - [ ] All edge cases covered
+ - [ ] Mock external API calls
+ - [ ] Tests run fast (< 5 seconds total)
+ 
+ ---
+ 
+ ### Task 3.2: Write Integration Tests
+ **Priority:** High  
+ **Estimated Effort:** 5 hours  
+ **Dependencies:** Task 3.1
+ 
+ **Description:**
+ End-to-end integration tests for complete synthesis pipeline.
+ 
+ **Files to Create:**
+ - `backend/tests/integration/test_chirp3_api.py`
+ 
+ **Test Scenarios:**
+ ```python
+ @pytest.mark.integration
+ async def test_chirp3_synthesis_full_pipeline():
+     """Test complete Chirp 3:HD synthesis pipeline"""
+     # Enable Chirp 3:HD for test
+     # Make synthesis request
+     # Verify audio generated
+     # Verify metrics recorded
+     # Verify cache works on second request
+ 
+ @pytest.mark.integration
+ async def test_custom_pronunciation_integration():
+     """Test custom pronunciations work end-to-end"""
+     request = SynthesizeRequest(
+         text="I read this book",
+         character_key="pip_boy",
+         custom_pronunciations=[
+             CustomPronunciation(phrase="read", pronunciation="rÉ›d")
+         ]
+     )
+     response = await synthesize_audio(request, ...)
+     assert response.voice_model == "chirp3-hd"
+ 
+ @pytest.mark.integration
+ async def test_fallback_mechanism():
+     """Test automatic fallback to WaveNet"""
+     # Mock Chirp 3:HD failure
+     # Verify fallback triggered
+     # Verify metrics recorded
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] All integration tests pass
+ - [ ] Tests cover happy path and error scenarios
+ - [ ] Real API calls (or realistic mocks)
+ - [ ] Test data cleanup automated
+ 
+ ---
+ 
+ ### Task 3.3: Performance Benchmarking
+ **Priority:** High  
+ **Estimated Effort:** 4 hours  
+ **Dependencies:** Phase 2 complete
+ 
+ **Description:**
+ Benchmark Chirp 3:HD performance vs WaveNet to verify targets met.
+ 
+ **Implementation Steps:**
+ 1. Create performance test suite
+ 2. Measure synthesis time for various text lengths
+ 3. Measure file sizes
+ 4. Compare Chirp 3:HD vs WaveNet
+ 5. Generate performance report
+ 
+ **Files to Create:**
+ - `backend/tests/performance/test_synthesis_performance.py`
+ - `backend/tests/performance/performance_report.md`
+ 
+ **Benchmarks:**
+ ```python
+ @pytest.mark.performance
+ def test_synthesis_performance_target():
+     """Verify synthesis meets < 2s target"""
+     text = "æ¨™æº–é•·åº¦çš„å¡”ç¾…è§£è®€æ–‡å­—ï¼Œå¤§ç´„äº”åå€‹å­—..."
+     
+     times = []
+     for _ in range(10):
+         start = time.time()
+         result = service.synthesize_speech(text, "pip_boy")
+         elapsed = time.time() - start
+         times.append(elapsed)
+     
+     avg_time = statistics.mean(times)
+     assert avg_time < 2.0, f"Average {avg_time:.2f}s exceeds 2s target"
+ 
+ @pytest.mark.performance
+ def test_cache_hit_rate():
+     """Verify cache hit rate > 90%"""
+     # Make 100 requests (10 unique, 10 repeats each)
+     # Calculate hit rate
+     # Assert > 90%
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] Synthesis time < 2 seconds for 90% of requests
+ - [ ] Cache hit rate > 90%
+ - [ ] File sizes reasonable (< 1KB per character)
+ - [ ] Performance report generated
+ 
+ ---
+ 
+ ### Task 3.4: Audio Quality Assessment
+ **Priority:** High  
+ **Estimated Effort:** 3 hours  
+ **Dependencies:** Phase 2 complete
+ 
+ **Description:**
+ Subjective audio quality testing with stakeholder feedback.
+ 
+ **Implementation Steps:**
+ 1. Generate sample audio for all 14 characters (Chirp 3:HD vs WaveNet)
+ 2. Create comparison test page
+ 3. Collect stakeholder feedback
+ 4. Document results and decisions
+ 
+ **Deliverables:**
+ - Audio samples for all characters (both models)
+ - Comparison web page (`/audio-comparison`)
+ - Feedback collection form
+ - Quality assessment report
+ 
+ **Acceptance Criteria:**
+ - [ ] Sample audio generated for all characters
+ - [ ] Stakeholder feedback collected
+ - [ ] Quality improvements documented
+ - [ ] Any voice mapping adjustments made
+ 
+ ---
+ 
+ ## Phase 4: Gradual Rollout (Week 5-6)
+ 
+ ### Task 4.1: Deploy to Staging with Chirp 3:HD Disabled
+ **Priority:** Critical  
+ **Estimated Effort:** 2 hours  
+ **Dependencies:** Phase 3 complete
+ 
+ **Description:**
+ Deploy complete codebase to staging with Chirp 3:HD feature flag OFF.
+ 
+ **Implementation Steps:**
+ 1. Deploy to staging environment
+ 2. Verify all existing functionality works
+ 3. Run smoke tests
+ 4. Check metrics dashboards
+ 
+ **Environment Variables:**
+ ```bash
+ CHIRP3_ENABLED=false
+ CHIRP3_FALLBACK_TO_WAVENET=true
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] Staging deployment successful
+ - [ ] All existing tests pass
+ - [ ] No regressions detected
+ - [ ] Metrics showing normal operation
+ 
+ ---
+ 
+ ### Task 4.2: Enable Chirp 3:HD for Test Character (pip_boy) at 10%
+ **Priority:** Critical  
+ **Estimated Effort:** 1 hour  
+ **Dependencies:** Task 4.1
+ 
+ **Description:**
+ Begin gradual rollout with single test character at 10% traffic.
+ 
+ **Implementation Steps:**
+ 1. Update feature flags in staging
+ 2. Monitor metrics for 24 hours
+ 3. Check for errors and fallbacks
+ 4. Collect performance data
+ 
+ **Environment Variables:**
+ ```bash
+ CHIRP3_ENABLED=true
+ CHIRP3_ENABLED_CHARACTERS=""
+ CHIRP3_ROLLOUT_PERCENTAGE=10
+ CHIRP3_FALLBACK_TO_WAVENET=true
+ ```
+ 
+ **Monitoring Checklist:**
+ - [ ] Synthesis success rate > 95%
+ - [ ] Average synthesis time < 2s
+ - [ ] Fallback rate < 5%
+ - [ ] No user complaints
+ - [ ] Cache hit rate maintained
+ 
+ **Acceptance Criteria:**
+ - [ ] 10% traffic routing to Chirp 3:HD
+ - [ ] Metrics showing healthy operation
+ - [ ] No critical issues detected
+ 
+ ---
+ 
+ ### Task 4.3: Increase to 50% for Test Character
+ **Priority:** High  
+ **Estimated Effort:** 1 hour  
+ **Dependencies:** Task 4.2 (24-hour soak test)
+ 
+ **Description:**
+ Increase rollout percentage after successful 10% test.
+ 
+ **Environment Variables:**
+ ```bash
+ CHIRP3_ROLLOUT_PERCENTAGE=50
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] 50% traffic routing to Chirp 3:HD
+ - [ ] Metrics remain healthy
+ - [ ] No increase in error rates
+ 
+ ---
+ 
+ ### Task 4.4: Enable for 3 Characters at 25%
+ **Priority:** High  
+ **Estimated Effort:** 1 hour  
+ **Dependencies:** Task 4.3 (48-hour soak test)
+ 
+ **Description:**
+ Expand to multiple characters after successful single-character test.
+ 
+ **Environment Variables:**
+ ```bash
+ CHIRP3_ENABLED_CHARACTERS="pip_boy,vault_dweller,wasteland_trader"
+ CHIRP3_ROLLOUT_PERCENTAGE=25
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] 3 characters using Chirp 3:HD at 25%
+ - [ ] Voice quality acceptable for all 3
+ - [ ] No character-specific issues
+ 
+ ---
+ 
+ ### Task 4.5: Enable All Characters at 50%
+ **Priority:** High  
+ **Estimated Effort:** 1 hour  
+ **Dependencies:** Task 4.4 (72-hour soak test)
+ 
+ **Description:**
+ Expand to all characters at 50% after successful multi-character test.
+ 
+ **Environment Variables:**
+ ```bash
+ CHIRP3_ENABLED_CHARACTERS=""  # Empty = all characters
+ CHIRP3_ROLLOUT_PERCENTAGE=50
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] All 14 characters using Chirp 3:HD at 50%
+ - [ ] Voice quality acceptable for all characters
+ - [ ] System performance stable
+ 
+ ---
+ 
+ ### Task 4.6: Increase to 100% Rollout
+ **Priority:** High  
+ **Estimated Effort:** 1 hour  
+ **Dependencies:** Task 4.5 (1-week soak test)
+ 
+ **Description:**
+ Complete rollout to 100% after successful 50% test.
+ 
+ **Environment Variables:**
+ ```bash
+ CHIRP3_ROLLOUT_PERCENTAGE=100
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] 100% traffic using Chirp 3:HD
+ - [ ] No increase in errors
+ - [ ] User feedback positive
+ - [ ] Ready for production deployment
+ 
+ ---
+ 
+ ### Task 4.7: Deploy to Production with Gradual Rollout
+ **Priority:** Critical  
+ **Estimated Effort:** 4 hours  
+ **Dependencies:** Task 4.6 (staging validation)
+ 
+ **Description:**
+ Deploy to production and repeat gradual rollout process.
+ 
+ **Implementation Steps:**
+ 1. Deploy to production with Chirp 3:HD disabled
+ 2. Verify deployment successful
+ 3. Begin 10% â†’ 50% â†’ 100% rollout over 2 weeks
+ 4. Monitor closely at each stage
+ 
+ **Rollout Schedule:**
+ - **Day 1-2:** 10% rollout, monitor closely
+ - **Day 3-7:** 50% rollout if stable
+ - **Day 8-14:** 100% rollout if stable
+ 
+ **Acceptance Criteria:**
+ - [ ] Production deployment successful
+ - [ ] Gradual rollout completed without issues
+ - [ ] Metrics showing improvement over WaveNet
+ - [ ] User feedback positive
+ 
+ ---
+ 
+ ## Phase 5: Cleanup and Documentation (Week 7+)
+ 
+ ### Task 5.1: Disable WaveNet Fallback
+ **Priority:** Medium  
+ **Estimated Effort:** 1 hour  
+ **Dependencies:** Task 4.7 (2-week stable operation)
+ 
+ **Description:**
+ Disable automatic fallback to WaveNet after Chirp 3:HD proven stable.
+ 
+ **Environment Variables:**
+ ```bash
+ CHIRP3_FALLBACK_TO_WAVENET=false
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] Fallback disabled
+ - [ ] Error handling adequate without fallback
+ - [ ] Monitoring confirms stability
+ 
+ ---
+ 
+ ### Task 5.2: Remove WaveNet-Specific Code
+ **Priority:** Low  
+ **Estimated Effort:** 3 hours  
+ **Dependencies:** Task 5.1 (1-week stable operation)
+ 
+ **Description:**
+ Clean up WaveNet-specific code while keeping for emergency rollback.
+ 
+ **Implementation Steps:**
+ 1. Comment out (don't delete) WaveNet synthesis code
+ 2. Update documentation
+ 3. Create rollback procedure document
+ 4. Archive WaveNet configuration
+ 
+ **Files to Modify:**
+ - `backend/app/services/tts_service.py`
+ 
+ **Acceptance Criteria:**
+ - [ ] WaveNet code commented but preserved
+ - [ ] Rollback procedure documented
+ - [ ] No active WaveNet code paths
+ - [ ] Tests updated
+ 
+ ---
+ 
+ ### Task 5.3: Update Documentation
+ **Priority:** Medium  
+ **Estimated Effort:** 4 hours  
+ **Dependencies:** Phase 4 complete
+ 
+ **Description:**
+ Comprehensive documentation update for Chirp 3:HD system.
+ 
+ **Documentation to Update:**
+ 1. API documentation (OpenAPI/Swagger)
+ 2. TTS service documentation
+ 3. Voice mapping rationale document
+ 4. Configuration guide
+ 5. Troubleshooting guide
+ 6. Migration guide (for reference)
+ 
+ **Files to Create/Update:**
+ - `backend/docs/tts_service.md`
+ - `backend/docs/chirp3_voice_mapping.md`
+ - `backend/docs/api/audio_endpoints.md`
+ - `.kiro/specs/chirp3-hd-tts-system/MIGRATION_GUIDE.md`
+ 
+ **Acceptance Criteria:**
+ - [ ] All documentation updated
+ - [ ] Code examples provided
+ - [ ] Voice mapping rationale documented
+ - [ ] Troubleshooting guide complete
+ 
+ ---
+ 
+ ### Task 5.4: Create Monitoring Dashboard
+ **Priority:** Medium  
+ **Estimated Effort:** 3 hours  
+ **Dependencies:** Task 1.4
+ 
+ **Description:**
+ Create Grafana dashboard for Chirp 3:HD system monitoring.
+ 
+ **Dashboard Panels:**
+ 1. **Synthesis Performance**
+    - Success rate by voice model
+    - Average synthesis time
+    - P50/P95/P99 latency
+ 
+ 2. **Voice Model Distribution**
+    - Chirp 3:HD vs WaveNet usage
+    - Per-character breakdown
+    - Rollout percentage tracking
+ 
+ 3. **Cache Performance**
+    - Cache hit rate by model
+    - Redis vs DB cache hits
+    - Cache size trends
+ 
+ 4. **Error Tracking**
+    - Error rate by model
+    - Fallback frequency
+    - Error types distribution
+ 
+ 5. **Audio Quality Metrics**
+    - File size distribution
+    - Duration accuracy
+    - Synthesis time per character
+ 
+ **Deliverables:**
+ - Grafana dashboard JSON
+ - Dashboard screenshot
+ - Dashboard usage guide
+ 
+ **Acceptance Criteria:**
+ - [ ] Dashboard created and imported
+ - [ ] All metrics displaying correctly
+ - [ ] Alerts configured for critical metrics
+ - [ ] Team trained on dashboard usage
+ 
+ ---
+ 
+ ## Risk Mitigation Tasks
+ 
+ ### Emergency Rollback Procedure
+ **Priority:** Critical  
+ **Estimated Effort:** 2 hours  
+ **Dependencies:** Phase 1 complete
+ 
+ **Description:**
+ Document and test emergency rollback procedure.
+ 
+ **Implementation Steps:**
+ 1. Create rollback runbook
+ 2. Test rollback in staging
+ 3. Identify rollback triggers
+ 4. Define rollback authority
+ 
+ **Rollback Triggers:**
+ - Synthesis error rate > 5%
+ - Fallback rate > 10%
+ - User complaints > threshold
+ - Performance degradation > 50%
+ 
+ **Rollback Steps:**
+ ```bash
+ # Immediate rollback (< 1 minute)
+ export CHIRP3_ENABLED=false
+ 
+ # Or character-specific rollback
+ export CHIRP3_ENABLED_CHARACTERS=""
+ export CHIRP3_ROLLOUT_PERCENTAGE=0
+ ```
+ 
+ **Acceptance Criteria:**
+ - [ ] Rollback procedure documented
+ - [ ] Rollback tested in staging
+ - [ ] Rollback triggers defined
+ - [ ] Team trained on rollback
+ 
+ ---
+ 
+ ## Summary
+ 
+ ### Total Estimated Effort
+ - **Phase 1:** 12 hours (Infrastructure)
+ - **Phase 2:** 26 hours (Implementation)
+ - **Phase 3:** 18 hours (Testing)
+ - **Phase 4:** 11 hours (Rollout)
+ - **Phase 5:** 11 hours (Cleanup)
+ - **Risk Mitigation:** 2 hours
+ 
+ **Total:** ~80 hours (~2 weeks for 1 developer, ~1 week for 2 developers)
+ 
+ ### Critical Path
+ 1. Task 1.1 â†’ 1.2 â†’ 1.3 â†’ 2.1 â†’ 2.2 â†’ 3.1 â†’ 4.1 â†’ 4.7
+ 2. Gradual rollout in Phase 4 requires patience (can't rush)
+ 
+ ### Success Metrics Review
+ - [ ] All 14 characters successfully using Chirp 3:HD
+ - [ ] Synthesis performance < 2s for 90% of requests
+ - [ ] Cache hit rate > 90% maintained
+ - [ ] Error rate < 1%
+ - [ ] Fallback rate < 5%
+ - [ ] User feedback positive
+ - [ ] Audio quality subjectively improved
+ 
+ ### Next Steps
+ 1. Review and approve this task breakdown
+ 2. Assign tasks to developers
+ 3. Set up project tracking (JIRA/Linear/GitHub Projects)
+ 4. Begin Phase 1 implementation
```

</details>

---

Tool use: **search_replace**


<details><summary>Edit file: .kiro/specs/chirp3-hd-tts-system/spec.json</summary>

**Chunk 1**
Lines added: 2, lines removed: 2

```diff
@@ -2,7 +2,7 @@
    "feature_name": "chirp3-hd-tts-system",
    "created_at": "2025-11-03T16:19:08Z",
-   "updated_at": "2025-11-03T16:21:25Z",
+   "updated_at": "2025-11-03T16:26:36Z",
    "language": "en",
-   "phase": "design_generated",
+   "phase": "tasks_generated",
    "approvals": {
      "requirements": {
```

**Chunk 2**
Lines added: 2, lines removed: 2

```diff
@@ -12,8 +12,8 @@
      "design": {
        "generated": true,
-       "approved": false
+       "approved": true
      },
      "tasks": {
-       "generated": false,
+       "generated": true,
        "approved": false
      }
```

</details>

---

Tool use: **todo_write**

## Todo List

- [x] Generate comprehensive requirements for Chirp 3:HD TTS system implementation
- [x] Generate technical design for Chirp 3:HD TTS system with voice mapping, pronunciation support, and rollout strategy
- [x] Generate implementation tasks breakdown with phases, dependencies, and acceptance criteria

---

ğŸ¤–

## å¯¦ä½œä»»å‹™å·²å®Œæˆç”Ÿæˆ

å·²ç”¢ç”Ÿå®Œæ•´çš„å¯¦ä½œä»»å‹™åˆ†è§£æ–‡ä»¶ï¼Œæ¶µè“‹ 5 å€‹éšæ®µå…± 30+ å€‹ä»»å‹™ï¼š

### ä»»å‹™ç¸½è¦½

**Phase 1: åŸºç¤è¨­æ–½èˆ‡é…ç½® (Week 1) - 12 å°æ™‚**
- Task 1.1: æ›´æ–° Google Cloud TTS ä¾è³´å¥—ä»¶
- Task 1.2: æ–°å¢ Chirp 3:HD èªéŸ³é…ç½®ï¼ˆ14 å€‹è§’è‰²å®Œæ•´æ˜ å°„ï¼‰
- Task 1.3: å¯¦ä½œåŠŸèƒ½æ——æ¨™ç³»çµ±ï¼ˆå…¨åŸŸ/è§’è‰²/ç™¾åˆ†æ¯”æ§åˆ¶ï¼‰
- Task 1.4: æ–°å¢ç›£æ§æŒ‡æ¨™ï¼ˆPrometheus metricsï¼‰

**Phase 2: æ ¸å¿ƒå¯¦ä½œ (Week 2-3) - 26 å°æ™‚**
- Task 2.1: å¯¦ä½œ `_synthesize_chirp3()` åˆæˆæ–¹æ³•
- Task 2.2: å¯¦ä½œèªéŸ³æ¨¡å‹è·¯ç”±èˆ‡è‡ªå‹•é™ç´š
- Task 2.3: é‡æ§‹ WaveNet ç¨‹å¼ç¢¼è‡³ç¨ç«‹æ–¹æ³•
- Task 2.4: å¯¦ä½œè‡ªè¨‚ç™¼éŸ³æ”¯æ´ï¼ˆIPA éŸ³æ¨™ï¼‰
- Task 2.5: å¯¦ä½œå¢å¼·èªéŸ³æ§åˆ¶ï¼ˆåœé “ã€åƒæ•¸è¦†å¯«ï¼‰
- Task 2.6: æ›´æ–°å¿«å– key è¨ˆç®—é‚è¼¯
- Task 2.7: æ›´æ–° API request/response schemas

**Phase 3: æ¸¬è©¦ (Week 4) - 18 å°æ™‚**
- Task 3.1: æ’°å¯«å–®å…ƒæ¸¬è©¦ï¼ˆè¦†è“‹ç‡ > 90%ï¼‰
- Task 3.2: æ’°å¯«æ•´åˆæ¸¬è©¦ï¼ˆç«¯å°ç«¯æµç¨‹ï¼‰
- Task 3.3: æ•ˆèƒ½åŸºæº–æ¸¬è©¦ï¼ˆ< 2s åˆæˆæ™‚é–“ï¼‰
- Task 3.4: éŸ³è¨Šå“è³ªè©•ä¼°ï¼ˆåˆ©å®³é—œä¿‚äººå›é¥‹ï¼‰

**Phase 4: æ¼¸é€²å¼ç™¼å¸ƒ (Week 5-6) - 11 å°æ™‚**
- Task 4.1: éƒ¨ç½²è‡³ Stagingï¼ˆChirp 3:HD é—œé–‰ï¼‰
- Task 4.2: å•Ÿç”¨æ¸¬è©¦è§’è‰² (pip_boy) 10% æµé‡
- Task 4.3: å¢åŠ è‡³ 50% æµé‡
- Task 4.4: å•Ÿç”¨ 3 å€‹è§’è‰² 25% æµé‡
- Task 4.5: å•Ÿç”¨å…¨éƒ¨è§’è‰² 50% æµé‡
- Task 4.6: å¢åŠ è‡³ 100% æµé‡
- Task 4.7: éƒ¨ç½²è‡³ Productionï¼ˆé‡è¤‡æ¼¸é€²æµç¨‹ï¼‰

**Phase 5: æ¸…ç†èˆ‡æ–‡ä»¶åŒ– (Week 7+) - 11 å°æ™‚**
- Task 5.1: åœç”¨ WaveNet è‡ªå‹•é™ç´š
- Task 5.2: ç§»é™¤ WaveNet ç‰¹å®šç¨‹å¼ç¢¼ï¼ˆä¿ç•™å›æ»¾èƒ½åŠ›ï¼‰
- Task 5.3: æ›´æ–°æ–‡ä»¶ï¼ˆAPIã€èªéŸ³æ˜ å°„ã€é…ç½®æŒ‡å—ï¼‰
- Task 5.4: å»ºç«‹ç›£æ§å„€è¡¨æ¿ï¼ˆGrafanaï¼‰

### é—œéµç‰¹æ€§

**1. å®Œæ•´ä»»å‹™åˆ†è§£**
- æ¯å€‹ä»»å‹™åŒ…å«ï¼šæè¿°ã€å„ªå…ˆç´šã€é ä¼°å·¥æ™‚ã€ä¾è³´é—œä¿‚
- è©³ç´°å¯¦ä½œæ­¥é©Ÿã€è¦ä¿®æ”¹çš„æª”æ¡ˆã€ç¨‹å¼ç¢¼ç¯„ä¾‹
- æ˜ç¢ºçš„é©—æ”¶æ¨™æº–èˆ‡æ¸¬è©¦æŒ‡ä»¤

**2. æ¼¸é€²å¼ç™¼å¸ƒç­–ç•¥**
- 10% â†’ 50% â†’ 100% è¬¹æ…æµé‡æ§åˆ¶
- æ¯éšæ®µ 24-72 å°æ™‚è§€å¯ŸæœŸ
- æ˜ç¢ºçš„å›æ»¾è§¸ç™¼æ¢ä»¶

**3. é¢¨éšªæ§ç®¡**
- ç·Šæ€¥å›æ»¾ç¨‹åºæ–‡ä»¶åŒ–
- å›æ»¾è§¸ç™¼å™¨å®šç¾©ï¼ˆéŒ¯èª¤ç‡ > 5%ã€é™ç´šç‡ > 10%ï¼‰
- < 1 åˆ†é˜å¿«é€Ÿå›æ»¾èƒ½åŠ›

**4. å“è³ªä¿è­‰**
- å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ > 90%
- æ•ˆèƒ½åŸºæº–æ¸¬è©¦ï¼ˆ< 2s åˆæˆæ™‚é–“ï¼‰
- éŸ³è¨Šå“è³ªä¸»è§€è©•ä¼°
- å¿«å–å‘½ä¸­ç‡ > 90%

### ç¸½é ä¼°å·¥æ™‚

**ç¸½è¨ˆï¼š~80 å°æ™‚**
- 1 ä½é–‹ç™¼è€…ï¼šç´„ 2 é€±
- 2 ä½é–‹ç™¼è€…ï¼šç´„ 1 é€±

**é—œéµè·¯å¾‘ï¼š** Task 1.1 â†’ 1.2 â†’ 1.3 â†’ 2.1 â†’ 2.2 â†’ 3.1 â†’ 4.1 â†’ 4.7

### æˆåŠŸæŒ‡æ¨™

- âœ… 14 å€‹è§’è‰²å…¨éƒ¨ä½¿ç”¨ Chirp 3:HD
- âœ… åˆæˆæ•ˆèƒ½ < 2sï¼ˆ90% è«‹æ±‚ï¼‰
- âœ… å¿«å–å‘½ä¸­ç‡ > 90%
- âœ… éŒ¯èª¤ç‡ < 1%
- âœ… é™ç´šç‡ < 5%
- âœ… ä½¿ç”¨è€…å›é¥‹æ­£é¢
- âœ… éŸ³è¨Šå“è³ªä¸»è§€æå‡

## ä¸‹ä¸€æ­¥

è¦æ ¼æ–‡ä»¶å·²å®Œæˆï¼Œå¯ä»¥é–‹å§‹å¯¦ä½œï¼š

```bash
# é–‹å§‹å¯¦ä½œï¼ˆåŸ·è¡Œç‰¹å®šä»»å‹™ï¼‰
/kiro:spec-impl chirp3-hd-tts-system 1.1,1.2,1.3

# æˆ–æŸ¥çœ‹è¦æ ¼ç‹€æ…‹
/kiro:spec-status chirp3-hd-tts-system
```

## å‚™è¨»

æ‰€æœ‰è¦æ ¼æ–‡ä»¶å·²æº–å‚™å°±ç·’ï¼ŒåŒ…å«éœ€æ±‚åˆ†æã€æŠ€è¡“è¨­è¨ˆã€ä»»å‹™åˆ†è§£ã€‚å»ºè­°æŒ‰ç…§ Phase 1 â†’ Phase 2 â†’ Phase 3 â†’ Phase 4 â†’ Phase 5 é †åºåŸ·è¡Œï¼Œæ¯å€‹éšæ®µå®Œæˆå¾Œé€²è¡Œé©—æ”¶æ¸¬è©¦ã€‚ç‰¹åˆ¥æ³¨æ„ Phase 4 çš„æ¼¸é€²å¼ç™¼å¸ƒéœ€è¦è€å¿ƒï¼Œä¸å¯è·³éè§€å¯ŸæœŸã€‚

---

