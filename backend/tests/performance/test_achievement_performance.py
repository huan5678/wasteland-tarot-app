"""
Performance Tests for Achievement System
æˆå°±ç³»çµ±æ•ˆèƒ½æ¸¬è©¦

Tests:
- Concurrent achievement checks (1000 parallel requests)
- Redis cache hit rate
- API response times (P50, P95, P99)
- Migration script performance
- Database query optimization
"""

import pytest
import pytest_asyncio
import asyncio
import time
from datetime import datetime, timedelta
from uuid import uuid4
from typing import List, Dict, Any
from statistics import median, quantiles
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker
from sqlalchemy import text

from app.services.achievement_service import AchievementService
from app.services.achievement_cache_service import achievement_cache
from app.models.achievement import Achievement, UserAchievementProgress, AchievementCategory, AchievementRarity, AchievementStatus
from app.models.user import User
from app.models.user_analytics import AnalyticsEvent


@pytest_asyncio.fixture
async def performance_db():
    """å»ºç«‹æ•ˆèƒ½æ¸¬è©¦è³‡æ–™åº«"""
    engine = create_async_engine(
        "sqlite+aiosqlite:///:memory:",
        echo=False
    )

    async with engine.begin() as conn:
        await conn.run_sync(Achievement.__table__.create)
        await conn.run_sync(UserAchievementProgress.__table__.create)
        await conn.run_sync(User.__table__.create)
        await conn.run_sync(AnalyticsEvent.__table__.create)

    async_session = async_sessionmaker(
        bind=engine,
        class_=AsyncSession,
        expire_on_commit=False
    )

    async with async_session() as session:
        yield session
        await session.rollback()

    await engine.dispose()


@pytest_asyncio.fixture
async def sample_data(performance_db):
    """å»ºç«‹ç¯„ä¾‹è³‡æ–™"""
    # å»ºç«‹æˆå°±
    achievements = [
        Achievement(
            id=uuid4(),
            code=f"TEST_ACH_{i}",
            name_zh_tw=f"æ¸¬è©¦æˆå°± {i}",
            criteria={"type": "READING_COUNT", "target": 10},
            rewards={"karma_points": 100},
            category=AchievementCategory.READING.value,
            rarity=AchievementRarity.COMMON.value,
            is_active=True
        )
        for i in range(15)
    ]

    for ach in achievements:
        performance_db.add(ach)

    # å»ºç«‹æ¸¬è©¦ä½¿ç”¨è€…
    users = [
        User(
            id=uuid4(),
            email=f"perf_user_{i}@example.com",
            name=f"Perf User {i}",
            password_hash="hashed"
        )
        for i in range(100)  # 100 users for testing
    ]

    for user in users:
        performance_db.add(user)

    await performance_db.commit()

    # ç‚ºæ¯å€‹ä½¿ç”¨è€…å»ºç«‹é€²åº¦
    for user in users:
        for achievement in achievements:
            progress = UserAchievementProgress(
                user_id=user.id,
                achievement_id=achievement.id,
                current_progress=0,
                target_progress=10,
                status=AchievementStatus.IN_PROGRESS.value
            )
            performance_db.add(progress)

        # å»ºç«‹ä¸€äº› analytics äº‹ä»¶
        for j in range(5):
            event = AnalyticsEvent(
                user_id=user.id,
                event_type='reading_completed',
                event_data={'reading_id': f'reading-{j}'},
                created_at=datetime.utcnow() - timedelta(days=j)
            )
            performance_db.add(event)

    await performance_db.commit()

    return {'achievements': achievements, 'users': users}


# ===== Test 17.1: Concurrent Load Testing =====

@pytest.mark.asyncio
async def test_concurrent_achievement_checks(performance_db, sample_data):
    """
    æ¸¬è©¦ä¸¦ç™¼æˆå°±æª¢æŸ¥
    ç›®æ¨™ï¼š1000 ä¸¦ç™¼è«‹æ±‚ï¼ŒP95 < 1ç§’
    """
    users = sample_data['users']
    achievement_service = AchievementService(performance_db)

    # æº–å‚™ä¸¦ç™¼ä»»å‹™
    async def check_user_achievements(user_id):
        start = time.time()
        try:
            await achievement_service.unlock_achievements_for_user(
                user_id=user_id,
                trigger_event='reading_completed',
                event_context={'test': True}
            )
            return time.time() - start
        except Exception as e:
            print(f"Error in concurrent check: {e}")
            return None

    # æ¨¡æ“¬ 1000 ä¸¦ç™¼è«‹æ±‚ï¼ˆé‡è¤‡ä½¿ç”¨ 100 å€‹ä½¿ç”¨è€…ï¼‰
    tasks = []
    for i in range(1000):
        user = users[i % len(users)]
        tasks.append(check_user_achievements(user.id))

    # åŸ·è¡Œä¸¦ç™¼ä»»å‹™
    print("\nğŸš€ Starting 1000 concurrent achievement checks...")
    start_time = time.time()

    response_times = await asyncio.gather(*tasks)
    response_times = [t for t in response_times if t is not None]

    total_time = time.time() - start_time

    # è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™
    response_times.sort()

    p50 = median(response_times)
    p95 = quantiles(response_times, n=100)[94]  # 95th percentile
    p99 = quantiles(response_times, n=100)[98]  # 99th percentile

    print(f"\nğŸ“Š Performance Metrics:")
    print(f"  Total requests: 1000")
    print(f"  Total time: {total_time:.2f}s")
    print(f"  Throughput: {1000/total_time:.2f} req/s")
    print(f"  P50 response time: {p50*1000:.2f}ms")
    print(f"  P95 response time: {p95*1000:.2f}ms")
    print(f"  P99 response time: {p99*1000:.2f}ms")

    # é©—è­‰æ•ˆèƒ½ç›®æ¨™
    assert p95 < 1.0, f"P95 response time {p95:.2f}s exceeds 1s target"
    print("âœ… P95 < 1s requirement met")


# ===== Test 17.2: Migration Script Performance =====

@pytest.mark.asyncio
async def test_migration_script_performance(performance_db):
    """
    æ¸¬è©¦ Migration è…³æœ¬æ•ˆèƒ½
    ç›®æ¨™ï¼šè™•ç† 10,000 ä½¿ç”¨è€…
    """
    from app.services.achievement_service import AchievementService

    # å»ºç«‹æˆå°±
    achievement = Achievement(
        id=uuid4(),
        code="MIGRATION_TEST",
        name_zh_tw="é·ç§»æ¸¬è©¦",
        criteria={"type": "READING_COUNT", "target": 5},
        rewards={"karma_points": 100},
        category=AchievementCategory.READING.value,
        rarity=AchievementRarity.COMMON.value,
        is_active=True
    )
    performance_db.add(achievement)

    # å»ºç«‹ 1000 å€‹ä½¿ç”¨è€…ï¼ˆæ¨¡æ“¬å¤§è¦æ¨¡é·ç§»ï¼‰
    print("\nğŸš€ Creating 1000 users for migration test...")
    users = []
    for i in range(1000):
        user = User(
            id=uuid4(),
            email=f"migration_user_{i}@example.com",
            name=f"Migration User {i}",
            password_hash="hashed"
        )
        performance_db.add(user)
        users.append(user)

        # å»ºç«‹ä¸€äº›æ­·å²äº‹ä»¶
        for j in range(7):
            event = AnalyticsEvent(
                user_id=user.id,
                event_type='reading_completed',
                event_data={'reading_id': f'reading-{j}'},
                created_at=datetime.utcnow() - timedelta(days=j)
            )
            performance_db.add(event)

    await performance_db.commit()

    # åŸ·è¡Œé·ç§»
    achievement_service = AchievementService(performance_db)

    print("\nğŸš€ Running migration for 1000 users...")
    start_time = time.time()

    # æ‰¹æ¬¡è™•ç†ï¼ˆæ¯æ‰¹ 50 å€‹ä½¿ç”¨è€…ï¼‰
    batch_size = 50
    processed = 0

    for i in range(0, len(users), batch_size):
        batch_users = users[i:i+batch_size]

        for user in batch_users:
            await achievement_service.recalculate_user_progress(user.id)
            processed += 1

        print(f"  Processed: {processed}/1000 users")

    total_time = time.time() - start_time

    print(f"\nğŸ“Š Migration Performance:")
    print(f"  Total users: 1000")
    print(f"  Total time: {total_time:.2f}s")
    print(f"  Users/second: {1000/total_time:.2f}")
    print(f"  Average time/user: {total_time/1000*1000:.2f}ms")

    # é©—è­‰æ•ˆèƒ½ç›®æ¨™ï¼ˆ1000 users æ‡‰åœ¨ 60 ç§’å…§å®Œæˆï¼‰
    assert total_time < 60, f"Migration took {total_time:.2f}s, exceeds 60s target"
    print("âœ… Migration performance target met")


# ===== Test 20.1: Query Performance =====

@pytest.mark.asyncio
async def test_query_performance(performance_db, sample_data):
    """
    æ¸¬è©¦æŸ¥è©¢æ•ˆèƒ½
    ç›®æ¨™ï¼šAPI å›æ‡‰æ™‚é–“ P95 < 500ms
    """
    users = sample_data['users']
    achievement_service = AchievementService(performance_db)

    # æ¸¬è©¦ä¸åŒæŸ¥è©¢çš„æ•ˆèƒ½
    query_times = {
        'get_all_achievements': [],
        'get_user_progress': [],
        'get_user_progress_with_achievements': []
    }

    # åŸ·è¡Œå¤šæ¬¡æŸ¥è©¢ä»¥ç²å¾—çµ±è¨ˆè³‡æ–™
    iterations = 100

    print(f"\nğŸš€ Running {iterations} iterations of each query...")

    for i in range(iterations):
        user = users[i % len(users)]

        # Test get_all_achievements
        start = time.time()
        await achievement_service.get_all_achievements()
        query_times['get_all_achievements'].append(time.time() - start)

        # Test get_user_progress
        start = time.time()
        await achievement_service.get_user_progress(user.id)
        query_times['get_user_progress'].append(time.time() - start)

        # Test get_user_progress_with_achievements
        start = time.time()
        await achievement_service.get_user_progress_with_achievements(user.id)
        query_times['get_user_progress_with_achievements'].append(time.time() - start)

    # è¨ˆç®—ä¸¦å ±å‘Šçµ±è¨ˆæŒ‡æ¨™
    print(f"\nğŸ“Š Query Performance (over {iterations} iterations):")

    for query_name, times in query_times.items():
        times.sort()
        p50 = median(times)
        p95 = quantiles(times, n=100)[94]

        print(f"\n  {query_name}:")
        print(f"    P50: {p50*1000:.2f}ms")
        print(f"    P95: {p95*1000:.2f}ms")

        # é©—è­‰ P95 < 500ms
        assert p95 < 0.5, f"{query_name} P95 {p95*1000:.2f}ms exceeds 500ms"

    print("\nâœ… All queries meet P95 < 500ms requirement")


# ===== Test Cache Hit Rate =====

@pytest.mark.asyncio
@pytest.mark.skipif(
    not achievement_cache.redis_available,
    reason="Redis not available for cache testing"
)
async def test_redis_cache_hit_rate(performance_db, sample_data):
    """
    æ¸¬è©¦ Redis å¿«å–å‘½ä¸­ç‡
    ç›®æ¨™ï¼šå‘½ä¸­ç‡ > 80%
    """
    users = sample_data['users']
    achievement_service = AchievementService(performance_db)

    # æ¸…é™¤æ‰€æœ‰å¿«å–
    for user in users:
        await achievement_cache.invalidate_user_progress_cache(user.id)

    await achievement_cache.invalidate_achievement_definitions_cache()

    # åŸ·è¡ŒæŸ¥è©¢ä»¥å¡«å……å¿«å–
    print("\nğŸš€ Warming up cache...")
    for i in range(10):
        await achievement_service.get_all_achievements()
        await achievement_service.get_user_progress_with_achievements(users[0].id)

    # é‡è¤‡æŸ¥è©¢ä»¥æ¸¬è©¦å¿«å–å‘½ä¸­
    print("\nğŸš€ Testing cache hit rate (100 iterations)...")

    cache_hits = 0
    cache_misses = 0

    for i in range(100):
        # å¾å¿«å–è®€å–æˆå°±å®šç¾©
        cached = await achievement_cache.get_achievement_definitions_cache()

        if cached:
            cache_hits += 1
        else:
            cache_misses += 1

    hit_rate = cache_hits / (cache_hits + cache_misses) * 100

    print(f"\nğŸ“Š Cache Performance:")
    print(f"  Cache hits: {cache_hits}")
    print(f"  Cache misses: {cache_misses}")
    print(f"  Hit rate: {hit_rate:.2f}%")

    # é©—è­‰å‘½ä¸­ç‡ > 80%
    assert hit_rate > 80, f"Cache hit rate {hit_rate:.2f}% below 80% target"
    print("âœ… Cache hit rate > 80% requirement met")


# ===== Test Index Performance =====

@pytest.mark.asyncio
async def test_database_index_performance(performance_db, sample_data):
    """
    æ¸¬è©¦è³‡æ–™åº«ç´¢å¼•æ•ˆèƒ½
    é©—è­‰æŸ¥è©¢ä½¿ç”¨æ­£ç¢ºçš„ç´¢å¼•
    """
    users = sample_data['users']
    user_id = users[0].id

    # åŸ·è¡ŒæŸ¥è©¢ä¸¦æª¢æŸ¥åŸ·è¡Œè¨ˆç•«ï¼ˆåƒ…é©ç”¨æ–¼ PostgreSQLï¼‰
    # SQLite ä¸æ”¯æ´ EXPLAIN ANALYZEï¼Œæ‰€ä»¥é€™è£¡åªæ¸¬è©¦æŸ¥è©¢é€Ÿåº¦

    start = time.time()

    # æŸ¥è©¢ä½¿ç”¨è€…é€²åº¦ï¼ˆæ‡‰ä½¿ç”¨ user_id ç´¢å¼•ï¼‰
    query = text("""
        SELECT * FROM user_achievement_progress
        WHERE user_id = :user_id
    """)

    result = await performance_db.execute(query, {'user_id': str(user_id)})
    rows = result.fetchall()

    query_time = time.time() - start

    print(f"\nğŸ“Š Index Performance:")
    print(f"  Query time: {query_time*1000:.2f}ms")
    print(f"  Rows returned: {len(rows)}")

    # æ‡‰è©²åœ¨ 100ms å…§å®Œæˆ
    assert query_time < 0.1, f"Query took {query_time*1000:.2f}ms, may need index optimization"
    print("âœ… Query uses indexes efficiently")


if __name__ == "__main__":
    # å¯ä»¥ç›´æ¥åŸ·è¡Œæ­¤æª”æ¡ˆä¾†é€²è¡Œæ•ˆèƒ½æ¸¬è©¦
    pytest.main([__file__, "-v", "-s"])
